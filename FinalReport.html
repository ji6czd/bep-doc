<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html lang="ja">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=iso-2022-jp">
	<link rev="made" href="mailto:takayuki@la.shonan-it.ac.jp">
	<meta name="author" content="Takayuki Watanabe">
	<meta name="keywords" content="IPA, BEP">
	<link rel="stylesheet" type="text/css" href="http://www.sfc.keio.ac.jp/~wata7be/report.css">
<!--	<link rel="stylesheet" type="text/css" href="report.css">
-->
	<title>BEP 未踏ソフト成果報告書 (案)</title>
</head>

<body>
<!-- $Id: FinalReport.html,v 1.32 2002/02/13 06:04:50 watanabe Exp $
-->


<h1>「日米2ヶ国語Emacs音声化システム<br>BEPによるLinuxの音声利用」<br>成果報告書 (案)</h1>

<p class="center">2001年度IPA未踏ソフトウェア創造事業 新部プロジェクトマネージャ分</p>
<p>2002年2月15日<br>
渡辺隆行、切明政憲</p>
<!-- + Mr.I -->

<DL class="note">
<DT><a NAME="TOC">目次</a>
 <DD>
     <UL>
      <LI><A HREF="#1Abstract">1. プロジェクトの目的及び概要</A>
	   <ul>
		 <li><A HREF="#11Background">1.1 開発の背景</A>
		 <li><A HREF="#12OpenProject">1.2 オープンプロジェクトBEP</A>
		 <li><A HREF="#13Objective">1.3 本プロジェクト開発の目的</A>
		</ul>
      <LI><A HREF="#2Structure">2. 全体構成</A>
      <LI><A HREF="#3Environment">3. 動作確認環境</A>
	   <ul>
		 <li><A HREF="#31LinuxBEP">3.1 Linux版BEP</A>
		 <li><A HREF="#32WinBEP">3.2 Windows版BEP</A>
		</ul>
      <LI><A HREF="#4Spec">4. 機能仕様</a>
	   <ul>
		 <li><A HREF="#41Tech">4.1 技術的目標</A>
		 <li><A HREF="#42Bilingual">4.2 ELisp部バイリンガル化機能の概要</A>
		 <li><A HREF="#43User">4.3 ユーザから見える変更</A>
		 <li><A HREF="#44LinuxSS">4.4 Linuxスピーチサーバの構成</A>
		 <li><A HREF="#45SScommands">4.5 Linuxスピーチサーバ制御コマンド一覧</A>
		</ul>
      <LI><A HREF="#5Install">5. 入手方法及びインストールの手順</a>
	   <ul>
		 <li><A HREF="#51LinuxInstall">5.1 Linux版BEPのインストール方法</A>
		 <li><A HREF="#52WinInstall">5.2 Windows版BEPのインストール方法</A>
		</ul>
      <LI><A HREF="#6Operation">6. 操作仕様</a>
	   <ul>
		 <li><A HREF="#61Engage">6.1 BEPの起動方法</A>
		 <li><A HREF="#62Voicify">6.2 基本的な読み上げコマンド</A>
		 <li><A HREF="#63Lang">6.3 言語切り替えなどのコマンド</A>
		 <li><A HREF="#64Applications">6.4 Emacsアプリケーションの音声利用例</A>
		</ul>
      <LI><A HREF="#7Examine">7. テスト及び診断方法</a>
	   <ul>
		 <li><A HREF="#71LinuxSS">7.1 Linuxスピーチサーバのテスト</A>
		 <li><A HREF="#72BEPExamine">7.2 BEPの動作テスト</A>
		</ul>
      <LI><A HREF="#8OpenSource">8. オープンソースによる福祉システム開発について</a>
	   <ul>
		 <li><A HREF="#81Bazzar">8.1 バザール型福祉システム開発の重要性</A>
		 <li><A HREF="#82BEPBazzar">8.2 BEPにおけるバザール型開発の実際</A>
		</ul>
      <LI><A HREF="#9Conclusion">9. まとめ</a>
	   <ul>
		 <li><A HREF="#91Results">9.1 開発成果</A>
		 <li><A HREF="#92Prospects">9.2 今後の課題</A>
		 <li><A HREF="#93ourTTS">9.3 音声合成への要望</A>
		</ul>
      <LI><A HREF="#10Data">10. 資料</a>
	   <ul>
		 <li><A HREF="#101Ref">10.1 開発成果の主な発表論文類</A>
		 <li><A HREF="#102Pronunciations">10.2 カタカナ発音とネイティブ発音を必要とする理由</A>
		 <li><A HREF="#103ML_WebAccess">10.3 BEPメーリングリストやWebアクセスの統計データ</A>
		</ul>
     </ul>
</dl>

<hr>

<h2><a name="1Abstract">1. プロジェクトの目的及び概要</a></h2>

<h3><a name="11Background">1.1 開発の背景</a></h3>

<p>MS-DOSは文字でコマンドを入力し文字で情報が出力されるOSであったので視覚障害者にも
使いやすいOSであった。1990年代に入ると初心者にも使いやすいGUI (Graphical User
Interface)を持ったWindowsが登場した。Windowsは最新の技術がいち早く導入される反面、
ウインドウ・アイコン・メニュー・ポインタなどのGUI部品による操作を前提にしている
場合が多いので、Windows標準の部品を使ったりスクリーンリーダに配慮して作成したり
しないと視覚障害者が使えないアプリケーションになってしまう。またバージョンアップ
の周期が早い巨大なOSに合わせてスクリーンリーダを開発するのは困難な作業である。そ
のため、Windows はなじみにくいとか使いにくいとか感じる人がいたり、新しいバージョ
ンでは使えない機能が生じたりする。実際、Windowsでなくてもできる作業ならばMS-DOSを使
うユーザも存在する。</p>

<p>Windows以外の高機能なOSとして、LinuxなどのUNIX系OSが注目を集めている。UNIXは
もともとテキストコンソールから操作するOSであり、文字情報だけでOSを管理できる。X
Window SystemなどのGUIはテキストの世界の上に別のレイヤとして存在しているだけで、
ユーザは好みに応じてテキストツールでもGUIツールでもUNIXを利用できる。したがって、
UNIXもMS-DOSと同じように音声利用できてMS-DOSを利用している視覚障害者が移行しやすいOSで
あるはずであるが、ユーザが少ないこともあってUNIX用のスクリーンリーダは数少なく、
日本語スクリーンリーダで実用化されているものがない。</p>

<p>つまり、視覚障害者にとってMS-DOSはOSとしての機能が低く新たに習得しても報われない、
WindowsのGUIは音声化システムに本質的に適していない、UNIXには音声化システムがほと
んどないといった状態になっており、最新コンピュータの機能を活用できる使いやすい日
本語音声化システムが待望されている。</p>

<p>職場での仕事には正確さと速度を求められるので、仕事で使う音声化システムは情報
を効率よく正確に音声化しなければならない。しかし既存の視覚障害者用音声化システム
は必ずしもこのような要求を満たしていない。また仕事や勉学の場で出会う情報は日本語
と英語が混在している場合が多い。ところが既存の音声化システムは日本語用に設計され
ているため英語を正しく音声化することが苦手であり、ローマ字を正しく読めるシステム
も少ない。したがって、ローマ字や日英2ヶ国語が混在した情報を正確に又わかりやすく
音声化できるシステムも必要とされている。</p>

<h3><a name="12OpenProject">1.2 オープンプロジェクトBEP</a></h3>

<p>そこで我々はこのような視覚障害者の要求を満たす音声化システムを開発するために、
1999年に晴眼者と視覚障害者が個人資格で集まったオープンソースのプロジェクトを立ち
上げ、日米二ヶ国語のEmacs音声化システムBEP(Bilingual Emacspeak Platform)の開発に
取り組んだ。

<p>BEPはRaman博士が開発した<a
href="http://emacspeak.sourceforge.net/">Emacspeak</a>を基にしており、既存の日本
語音声化システムと比較して以下の特徴を持つ。</p>

<OL>
 <li>GUIに対するAUI(聴覚専用UI)を持ち、聴覚に最適化して情報を提供できる。
 <li>Emacsが扱う多言語情報を、各言語のテキスト音声合成エンジンで出力できる。
 <li>バザール型の開発であり、視覚障害者自身が開発の中心にいてユーザが本当に必要
とする機能を実装している。また成果をオープンソースとして公開している。
 <li>WindowsでもLinuxでも、同じ操作性でEmacsを音声出力で利用できる。
</ol>

<h3><a name="13Objective">1.3 本プロジェクト開発の目的</a></h3>

<p>BEPは2001年1月にアルファ版を公開したが、視覚障害者に利用してもらうためにはま
だまだ多くの改良が必要である。そこで本開発では、Linux版とWindows版のスピーチサーバ
の改良、Emacs Lisp部の改良、スピーチサーバ及びBEP Emacs Lisp部の多言語化、視覚障
害者用インストーラの作成、ユーザテストとユーザサポートなどに取り組んだ。
以下、今回の開発内容についてLinux版BEPを中心に述べる。
なお、開発成果のまとめは<a href="#91Results">9.1節の「開発成果」</a>に示す。</p>


<p><a href="#TOC">[目次に戻る]</a></p>

<h2><a name="2Structure">2. 全体構成</a></h2>

<p>図1に示すように、BEPはEmacspeakをバイリンガルに拡張したEmacs Lisp (ELisp)部と、
日本語と英語の音声合成エンジンを制御するスピーチサーバ部の2つのソフトウェアに分
かれる。Emacs Lisp部は両OSで共通しているが、スピーチサーバはOSごとに異なる。音声
合成ライブラリは市販の製品を用いる。Windows版のスピーチサーバはMicrosoftのSpeech
API 4に準拠した音声合成ライブラリを使用する。Linux版は、<a href="#44LinuxSS">4.4
節「Linuxスピーチサーバの構成」</a>に示すように独自のインターフェースを持つ。図
中、太線枠部が今回開発した部分。</p>

<p class="center"><img src="BEP_config.png" width="446" height="218" alt="BEPは
Elisp部とスピーチサーバ部に分かれている。Elisp部、SS、Linux用のTTSインターフェー
ス、Linux日本語TTSを開発した。"> <br>
図1. BEP構成図</p>

<p><a href="#TOC">[目次に戻る]</a></p>

<h2><a name="3Environment">3. 動作確認環境</a></h2>

<p>本システムはWindowsでもLinuxでも使えるEmacsの音声化システムであり、今回開発し
た部分(Emacs Lispライブラリ、各OS用のスピーチサーバ)以外に、Emacsと日本語と英語
の音声合成ライブラリが必要である。以下の環境で動作を確認している。</p>

<h3><a name="31LinuxBEP">3.1 Linux版BEP</a></h3>

<ul>
 <li>CPU: Pentium MMX 266MHz 以上
 <li>Memory: 128MB 以上
 <li>必要なハードディスク容量: 20MB程度
</ul>

<p>以下のソフトが事前にインストールされている必要がある。これらのインス
トールに約70MB程度が必要である。</p>

<ul>
 <li>Emacs: Emacs 20.6, 20.7 21.1
 <li>日本語音声合成エンジン: クリエートシステム開発(株)の Document Talker for Linux
 <li>英語音声合成エンジン: IBMの Viavoice Outloud
</ul>

<p>以下のディストリビューションで動作確認を行った。</p>

<ul>
 <li>RedHat 6.20, 7.2(J)
 <li>Vine Linux 2.1.5
</ul>

<h3><a name="32WinBEP">3.2 Windows版BEP</a></h3>

<ul>
 <li>OS: Windows 98SE, Windows ME, Windows 2000
 <li>CPU: Pentium II 233MHz 以上
 <li>Memory: 128MB 以上
 <li>必要なハードディスク容量: 20MB程度
 <li>Microsoft Speech API 4 (注; SAPI 3や SAPI 5では正常に動作しない。)
</ul>

<p class="Todo">注; 現在、Windows版は日本語音声合成ライブラリの種類及び英語の発
音方法が異なる2種類のスピーチサーバが存在する。IBMの音声合成を用いるWindows版(1)
を安定して使用するには、Pentium II 400MHzクラスのCPUが必要。また、Windows版スピー
チサーバは今回新たに開発したELisp部の言語切り替えコマンドなどにまだ対応していな
いので、2001年度に公開しているバージョンのELispを使う必要がある。</p>

<p>以下のソフトが事前にインストールされている必要がある。これらのインストールに
約100MBの空き領域が必要。</p>

<ul>
 <li>Emacs: Meadow 1.14, 1.15Pre1以上 (50MB程度必要)
 <li>日本語音声合成エンジン: IBM ProTalker97 Ver. 2.04以上 (40MB程度必要)
 <li>英語音声合成エンジン: Microsoft Text-to-Speech Engine (10MB程度必要)
</ul>
<!-- Meadow44MB、SAPI8MB、HPR35MB、東芝LaLaVoice160MB、BEP14M、-->

<p><a href="#TOC">[目次に戻る]</a></p>

<h2><a name="4Spec">4. 機能仕様</a></h2>

<h3><a name="41Tech">4.1 技術的目標</a></h3>

<p>
バイリンガル化したEmacspeakがパソコンを音声利用するユーザに有用で、拡張性の高いものに
なるように、以下の点に留意して開発した。
</p>

<p>
まず、BEPはバイリンガルシステムである以前に日本語音声化システムとして実
用に耐えるものでなければならない。ソースコードフリーで提供されている
日本語環境で利用可能なLinux音声化システムは、2002年2月現在においてBEP以外
に存在しない。従って、Linux上でBEPを使うユーザの多くにとって、BEPがメイ
ンの作業環境を音声化する手段となる可能性がある。日本語処理のために十分な
機能を提供できなければ、そのような利用に耐えうるものにはならない。このた
め、BEPでは文字の詳細読み、記号類の言語に依存した読み変えなどの機能をサ
ポートした。また、操作のレスポンスを向上するため、音声出力中に後のイベン
トや操作によって瞬時に先の音声を停止して次のイベントに即した読み上げを開
始する即時停止機能にも重点を置いた。
</p>

<p>
また、上のこととも関係するが、英語の聞き取りが不得意なユーザにも有用なも
のとすることも重要である。既存の日本のスクリーンリーダーは、英語文字列
をカタカナの読みに変換し、日本語音声合成ソフトウェアを用いて発声する。
BEPはバイリンガルであるため、英語文字列は英語発音で発声するが、英語が不
得意なユーザにとってはカタカナ読みの方が情報を得やすい場面もある。また、
<a href="#102Pronunciations">10.2節「カタカナ発音とネイティブ発音を必要とする理由」</a>に
示すように日本語文中に現れる英単語などは周囲と同じ日本語音声合成でカタカナ読みする
のが望ましい場合が多い。そのため、BEPでは英語文字列についてネイティブな
読みとカタカナ読みの二つを使い分けることを可能にした。
また、日本人の英語聞き取り能力に配慮して、音声出力速度を日英独立に指定できるようにした。
</p>

<p>
さらに、今回の日英のバイリンガル化の次のステップとして将来的に同じ枠組みで他
の言語環境へ拡張可能とすることを考慮し、Emacspeakに英語以外
の言語サポートを加えるための変更、日本語に特化した機能をLispファイルや名
前空間のレベルで分離した。
</p>

<p>
今回の開発成果をより多くの人に利用してもらい、今後も発展していくためには、
基盤としているEmacspeakの変更をすぐに取り入れられることが望ましい。
そのため、Emacspeak本体に対しては多言語対応機能が動作するための最低限の
変更にとどめ、多言語化及び日英バイリンガル特有の機能はモジュールとして別
にロードして有効化する形とした。
</p>

<p>
以下の節ではこれらの機能を実現するためにlisp部及びスピーチサーバ部をどの
ように構成したかの概要、その外部仕様について述べる。
</p>

<h3><a name="42Bilingual">4.2 ELisp部バイリンガル化機能の概要</a></h3>

<h4>4.2.1 プロパティを利用した言語切り替え</h4>

<p>
EmacspeakのLisp部は大きく二つの部分から構成されている。一つは直接スピー
チサーバ(SS)を制御するSS制御部、もう一つはEmacsの動作
(関数)をトリガとして呼び出され、必要な情報をSS制御部のために準備するフロ
ントエンド部である。
</p>

<p>
Emacspeakには情報の種類によって声の種類やパラメータを変えて出力する機能
がある。たとえば、プログラムを読み上げさせると、コメントの部分は抑揚のな
い棒読みで、文字列定数は女性の声でといったように区別される。この機能を
voice-lockと呼んでいる。バイリンガル拡張の実現ではこのvoice-lockにヒント
を得ている。
</p>

<p>
voice-lockではフロントエンド部でバッファの内容を解析し、デフォルト以外の
声で出力したい部分のテキストにpersonality属性を与える。SS制御部ではこの
personality属性を検知し、スピーチサーバに送るコマンドに声の種類を変更す
るためのin-textコマンドを挿入して声を変化させる。
</p>

<p>
今回開発したバイリンガル化拡張では、フロントエンド部を拡張し、バッファの
内容を見て、文字種や周囲の状況から判断してemacspeak-language属性をセット
する。この属性には値として言語名(現在はenまたはja)がセットされる。次に、
SS制御部ではこの属性の変化するところでスピーチサーバに対して言語変更を示
すコマンドを送信することで、その前後で出力すべき言語が異なることをスピー
チサーバに伝えることができる。
</p>

<p>
つまり、一度emacspeak-language属性が付与されたテキストは、これまでの音声
種別による情報提示と直行する形で言語種別の概念を持つことになる。
</p>

<h4>4.2.2 言語属性付与の仕組み</h4>

<p>
フロントエンド部において常に言語属性を自動的に付与することが困難な場合がある。
なぜなら、GNU Emacsがバッファに保持している各文字の文字セット情報からその
部分が属している言語を判定することは自明ではないためである。そのた
め、BEPの今回の方式では、日本語と英語のみが存在すると仮定した上で言語属
性を設定することとした。
</p>

<p>
言語の判定には主としてEmacsの持つ文字カテゴリを用いる。日本語の文字カテ
ゴリ(japanese-jisx0208, katakana-jisx0201等)に属する文字は日本語としてし
か読み上げることができないため、無条件で日本語と判定する。それ以外の文字
(ASCIIなど)については二つの扱い方が考えられる。一つは英語と判定してオリ
ジナルEmacspeakと同じ処理を行うこと、もう一つは日本語と判定し、カタカナ
読み(英単語、ローマ字)や日本語らしい記号読み(半角記号類)で日本語として読
み上げることである。
</p>

<p>
BEPではバッファの変更、ウインドウのスクロールやリサイズに応じて言語属性
を付与する機能が呼び出されるが、言語属性の付与機能を以下の３種類の中からユーザの指定に応
じて切り替え可能とした。バッファローカル変数とすることで、バッファごと、
モードごとに設定することもできる。
また、後から追加することも可能である。現在提供し
ている三つの方式を以下に示す。
</p>

<ol>
<li>ネイティブ英語モード: ASCII文字はすべて英語と判定し、英語の音声合成を用いて
    読み上げる。
<li>混在モード: 一定の長さ(デフォルト40文字)以下のASCII文字の連続は日本
    語と判定し、カタカナ読みで日本語の音声合成に送る。これは、段落全体がASCII文
    字であるような場合には英語で発音してほしいが、日本語文中に現れる短い
    英文字列は日本語化した語で日本語の一部として読み上げる方が自然と思わ
    れる場合が多いためである。このモードをデフォルトとしている。
<LI>すべてカタカナモード: ASCII文字列もすべてカタカナ読みとして日本語の音声合成
    で出力するモードである。プログラムなど特定の環境では日本人のユーザに
    とってこの方が実用的な場合がある。
</ol>

<h4>4.2.3 その他Lisp部多言語対応について</h4>

<p>
本プロジェクトにおけるEmacspeakに対する拡張は、4つの部分に分けることがで
きる。それらに関して概略を述べる。
</p>

<ol>
<li>
Emacspeak本体に対する変更: 主にこれまでに述べた言語属性の
付与と利用に関する切り口を提供することが目的である。
また、言語属性に応じて実際に言語変更をスピーチサーバに通知したり、必要に
応じてそれぞれの言語での読み上げ速度を設定する部分は直接スピーチサーバと
関わるためにこの部分に含まれる。
この部分は今後さらに小さくまとめた上で、オリジナルEmacspeakに統合しても
らう方向で依頼する。
<li>
多言語拡張のフレームワーク: 言語に依存しないインター
フェースをEmacspeak本体に対して提供する。Emacspeak本体はこのレイヤの関数
のみを呼び出し、言語に依存した処理への分岐はこのレイヤで行う。抽象化され
た関数には、主に文字や記号の言語に適した読み方の取得(例: 「(」を「left
paren」と読むか「カッコ」と読むかなど)、カーソル移動時や入力時に適した読
み方の取得、言語属性付与のためのラッパーなどが含まれる。
<li>
日本語特有の部分: 多言語化フレームワークから呼び出される。
ここには日本語として適切な文字の読み方やカーソル移動/日本語変換時のフィー
ドバックに適した読み方の取得、前節で述べた言語属性の付与に関する三つの方
式の実装などが含まれる。
<li>
日本語環境でよく用いられてEmacspeakがサポートしていないELispアプ
リケーションのサポートファイル群: 日本語変換システムであるtamago
V4の音声フィードバックサポート、Mew、 emacs-w3m等のサポートが含まれる。
</ol>

<h3><a name="43User">4.3 ユーザから見える変更</a></h3>

<p>
本プロジェクトで開発したBilingual Emacspeak Platformではオリジナル
Emacspeakの機能を日本語英語の混在環境でもシームレスに利用可能とする方向
で拡張を行った。そのためユーザから見える部分での操作的変更は比較的少なく
なっている。
</p>

<p>
以下は多言語拡張に関連したinteractiveコマンドの一覧である。
</p>

<dl>
<dt>emacspeak-m17n-auto-put-language-mode</dt>
<dd>
バッファの変更、ウインドーのスクロール、リサイズなどのイベントに合わせて、
表示されている部分に自動的に言語プロパティを付与する機能をon/offする。同
名の変数をトグルするとともに、関連するフックの設定と解除を行う。
</dd>
<dt>emacspeak-m17n-ja-toggle-strategy</dt>
<dd>
日本語と英語のバイリンガル環境において、利用可能なput-language-strategy
をトグルする。詳しくはカスタマイズ変数の項を参照。
</dd>
 <dt>emacspeak-m17n-put-language-region</dt>
<dd>
現在の<code>emacspeak-m17n-put-language-strategy</code>に従って指定した
領域に言語プロパティを付与する。
</dd>
<dt>emacspeak-m17n-sync-rate-offset</dt>
<dd>
言語ごとの発声速度オフセットが指定されている場合に、それをスピーチサーバ
に反映するコマンドを送信する。
</dd>
</dl>

<p>
以下はバイリンガル拡張で導入された、ユーザで設定可能な変数の一覧である。
</p>

<dl>
<dt>dtk-speaker-process-coding-system</dt>
<dd>スピーチサーバに送信されるコマンド文字列のcoding-system。現在の
    Windows及びLinux用スピーチサーバではShift_JISを用いる。</dd>
<dt>dtk-default-language</dt>
<dd>言語属性が張られていない文字を読むときのデフォルト言語</dd>
<dt>emacspeak-m17n-auto-put-language-mode</dt>
<dd>自動的に言語属性を付与するかどうかを示す。直接変更せず、
    emacspeak-m17n-auto-put-language-modeコマンドで変更する。</dd>
<dt>emacspeak-m17n-put-language-strategy</dt>
<dd>言語属性を付与する関数を指定する。指定された関数には、引数として領域
    の先頭と最後のポイント、変更前の領域の長さが渡される。</dd>
<dt>emacspeak-m17n-put-language-internal-strategy</dt>
<dd>バッファではなくEmacsが表示するメッセージなど、言語属性が付与されな
    い状態でSS制御部に直接渡された文字列に適用する属性付与関数を指定する。
    仮定される引数はemacspeak-m17n-put-language-strategyと同じ。</dd>
<dt>emacspeak-m17n-rate-offset-alist </dt>
<dd>言語とそれに対応した速度オフセットのalist<br>
例: ((ja 0) (en -30))</dd>
<dt>emacspeak-m17n-ja-strategy-list</dt>
<dd>日本語とのバイリンガル環境で、emacspeak-m17n-ja-toggle-strategyで選
    択できる言語属性付与関数のリスト</dd>
<dt>emacspeak-m17n-ja-ke-limit</dt>
<dd>言語属性付与が混在モードの時、何文字以上のASCII文字列を英語として扱
    うかの指定。デフォルトは40</dd>
<dt>emacspeak-m17n-ja-ke-view</dt>
<dd>言語属性付与が混在モードで変更前の長さがke-limitより短い時、ポイント
    位置から上下になん行を見て判定するかの指定。デフォルトは3で、上下２
    行を見る。</dd>
</dl>

<h3><a name="44LinuxSS">4.4 Linux スピーチサーバの構成</a></h3>

<p>
スピーチサーバはBEPの音声出力を行う独立したプログラムで、Emacsのサブプロ
セスとして起動される。
BEPのSS制御部からコマンド入力を受け、日英の音声合成(TTS)ライブラリを制御し、生成
されたPCMデータをサウンドデバイスへ書き込む。また、コマンドに従って出力
の即時停止を行う。
本説では新たに開発したLinux用バイリンガルスピーチサーバの構成について解
説する。
</p>

<h4>4.4.1 制御の仕組み</h4>

<ul>
 <li>Linux用スピーチサーバは、コマンド処理部、コントローラ部、TTSラッパー部、
TTSソフトウェア、サウンドデバイス制御部から構成される。
 <li>コマンド処理部はEmacspeakからのコマンドを１行ずつ受け取り、コントロー
ラ部のメソッドにマップする役割を持つ。
 <li>コントローラ部はコマンドに応じて、リクエストの作成とキューイング、共通
TTSインターフェースを介したTTSの管理リクエストの送信を行う。
 <li>TTSラッパー部はTTSソフトウェアと一対一に対応し、共通TTSインターフェース
を提供する。それぞれがコマンド処理部とは独立したスレッドとして動作する。
<li>サウンドデバイス制御部はサウンドデバイスへの出力を一元管理し、出力要求の
順序を管理する。また、サウンドデバイスドライバの違いを吸収する。
</ul>

<h4>4.4.2 共通TTSインターフェース</h4>

<p>
Linuxスピーチサーバで利用する日本語と英語のTTSソフトウェ
アは日本語と英語で全く異なるAPIを備えている。
</p>

<dl>
<dt>日本語</dt>
<dd>クリエートシステム開発株式会社が販売するLinux用の日本語音声合成ライブラリであ
    る。日本語文字列を解析して独自の表音文字列に変換する言語処理ライブラ
    リと、表音文字列を入力としてPCMデータを生成する波形処理部からなる。
    APIは言語処理と波形処理それぞれに対して定義されている。
    ライブラリ自身は音声をサウンドデバイスへ出力する機能を持たない。音声
    の種類や速度を変更するには波形処理部のライブラリ関数を呼ぶか、波形処
    理部に入力する表音文字列に制御文字列を付加する。</dd>
<dt>英語</dt>
<dd>
IBMのViaVoice Outloudを利用する。文字列の入力、キューイング、波形出
力を統合的に制御するEloquence Command Interface(ECI)と呼ばれるAPIを持つ。
生成した波形をサウンドデバイスに出力する機能を持つ。音声の種
類や速度の変更は入力に「`」で始まるコマンド文字列を挿入することで読み上
げ文字列と同期して行うことができる。
</dd>
</dl>

<p>
このように異なる機能を持つTTSを制御するため、別に共通のAPIを定め、それに
会わせたラッパークラスをTTSごとに作成して、上位のレイヤーからは共通APIの
みを利用することとした。
</p>

<p>
共通TTSインターフェースではそれぞれのTTSが独立したスレッドとして動作する。
そのうえで、リクエストのキューイング、音声合成処理、即時停止の機能を提供する。
TTSへのリクエストは発声すべき文字列、発声速度、言語、タイプ(文字列として
読むか１文字として扱うのか)、句読点の読み方に関するパラメータなどを含む。
リクエスト中の文字列には、読み上げるべき文字列以外に、TTSソフトウェ
アを制御するためのin-textコマンドも含まれる。これはDECTalkのサポートする
コマンドのサブセットであり、<code>[, ]</code>で囲まれる。これらのコマン
ドはリクエストからそれぞれのTTSラッパーに渡され、そこでTTSソフトウェアに
適した形式(別のin-textコマンドまたはライブラリ用APIのコール)に変換する。
</p>

<p>
共通TTSインターフェースでは以下の機能を定義する。
</p>
<ul>
<li>エンジンがサポートする言語の設定と取得
<li>発声速度オフセットの指定
<li>出力先サウンドデバイスの指定
<li>TTSスレッドの開始と停止
<li>文字列のキューイング
<li>発声開始
<li>発声停止フラグのセット
</ul>

<p>
TTSのスレッドが開始されるとそれぞれのTTSソフトウェアを初期化し、内部の
キューにリクエストが入力されるのを待つ。上位の制御でリクエストが入力され、
発声開始が要求されると、サウンドデバイスの待ち順を予約し、リクエストを順
に処理して音声出力を行う。また、発声停止要求があれば、キューイングされた
リクエストを破棄してリクエスト待ち状態に移行する。
</p>

<h4>4.4.3 コントローラ部と多言語の扱い</h4>

<p>
コントローラ部は発声リクエストのキュー、使用可能なTTSのリスト、現在の発
声パラメータを保持している。それぞれ入力されたコマンドによって設定するこ
とができる。パラメータの主なものを以下に示す。
</p>

<dl>
<dt>現在の言語</dt>
<dd>次にコマンドによってキューイングされる文字列を読み上げる言語を指定す
    る。現在はja, enのみサポート。</dd>
<dt>発声速度</dt>
<dd>WPM(Word per Minute)で指定される発声速度。これを元に各TTSの速度が決
    定される。</dd>
<dt>記号類読みモード</dt>
<dd>記号や句読点の読み上げをどの程度行うか。none, some, allの三つのモー
    ドがあり、noneでは句読点や括弧類などの記号を読み上げず、allではそれ
    らすべてを正確に発声する。</dd>
<dt>大文字による複合語分離指定(split_caps)</dt>
<dd>英字複合語を大文字のところで区切って解析し読み上げるかどうかの指定。
  「ssDspDevice」といった記法でも意味が分かるように読み上げることができ
  る。</dd>
<dt>１文字読み上げ時の速度倍率</dt>
<dd>コマンドで１文字のみの読み上げ(大半はEmacsへのキー入力操作のエコーバッ
  ク)が指定されたとき、現在の発声速度にこの倍率をかけた速度にして発声す
  る。通常は1より大きい値を指定することでキーエコーバックを高速化する。</dd>
</dl>

<p>
コントローラ部ではコマンドとして文字(列)のキューイングが要求されると、与
えられた文字(列)と上記のパラメータをリクエストとしてキューにプッシュする。
コマンドとして発声が要求されると、キューから一つずつリクエストをポップし
て、そこに指定された言語に従ってそれぞれのTTSラッパーに送る。最後にすべ
てのTTSラッパーに発声開始を要求することで文字列が順次適切なTTSで読み上げ
られる。
</p>

<h3><a name="45SScommands">4.5 Linuxスピーチサーバ制御コマンド一覧</a></h3>

<p>
以下はLinux スピーチサーバのコマンド処理部が解釈するコマンドの一覧である。
</p>

<dl>
<dt><code>q {&lt;string&gt;}</code></dt>
<dd>文字列stringと現在のパラメータをキューに入れる。</dd>
<dt><code>d</code></dt>
<dd>キューの中身を順にしゃべる。</dd>
<dt><code>s</code></dt>
<dd>しゃべっている音声の即時停止とキューのクリア</dd>
<dt><code>l {&lt;C&gt;}</code></dt>
<dd>1文字Cを即時発声（大文字の区別、速度加速あり）</dd>
<dt><code>tts_say {&lt;string&gt;}</code></dt>
<dd>文字列stringを即時発声</dd>
<dt><code>t &lt;freq&gt; &lt;msec&gt;</code></dt>
<dd>トーンサインをキューに入れる(予約)。</dd>
<dt><code>tts_set_speech_rate &lt;NNN&gt;</code></dt>
<dd>音声速度をNNN(WPM)に設定</dd>
<dt><code>tts_set_punctuations &lt;all|some|none&gt;</code></dt>
<dd>記号類読み上げモード指定</dd>
<dt><code>tts_set_language &lt;en|ja&gt;</code></dt>
<dd>現在の言語を指定</dd>
<dt><code>tts_set_character_scale &lt;N.N&gt;</code></dt>
<dd>lコマンドの読み上げ増速倍率を設定</dd>
<dt><code>tts_sync_state &lt;punc-mode&gt; &lt;capitaloze&gt;
    &lt;allcaps-beep&gt; &lt;split-caps&gt; &lt;rate&gt;</code></dt>
<dd>パラメータの一括設定。punc-modeは記号類読みモード(all|some|none)、
split-capsは大文字による区切り読み指定(0:off, 1:on)、rateは読み上げ速度
(WPM)。その他は実装していない。</dd>
<dt><code>tts_set_speed_offset &lt;lang&gt; &lt;offset&gt;</code></dt>
<dd>言語ごとの速度オフセット値指定。言語lang(ja|en)の速度オフセットを
offsetに設定する。-20と指定すると、その言語による読み上げはその時点での
速度値より20WPM遅くなる。</dd>
</dl>

<p><a href="#TOC">[目次に戻る]</a></p>

<h2><a name="5Install">5. 入手方法及びインストールの手順</a></h2>

<p>当プロジェクトで開発した部分はGNU GPLに従って、<a
href="http://www.argv.org/bep">BEPのWebサイト</a>で公開している</p>

<h3><a name="51LinuxInstall">5.1 Linux版BEPのインストール方法</a></h3>

<p>Linux版のインストール手順は大きく分けて三つのプロセスになる。日本語と
英語のTTSエンジンのインストール、Linux用スピーチサーバのコンパイルとイン
ストール、BEPのlispパッケージのインストールである。それぞれについて解説
する。</p>

<h4>5.1.1 日本語TTSエンジンのインストール</h4>

<p>
BEPの日本語読み上げ機能を利用するには、クリエートシステム開発株式会社が
販売している日本語音声合成ライブラリが必要である。
クリエートシステム開発のLinux版のページ
<a href="http://www.createsystem.co.jp/linux.html">
http://www.createsystem.co.jp/linux.html</a>
からVectorのプロレジを通じて安価に購入できる。(\4,800)
</p>

<p>
BEPが想定している構成に合わせ、製品に含まれるファイルを以下のように配置する。
</p>

<ol>
<li>ディレクトリ<code>/usr/local/lib/dtalker</code>,
<code>/usr/local/include/dtalker</code>を作成
<li><code>synch/lib/*</code> → <code>/usr/lib</code>
<li><code>synth/include/*</code> → <code>/usr/local/include/dtalker</code>
<li><code>synth/dic/*</code> → <code>/usr/local/lib/dtalker</code>
<li>ldconfigを実行
</ol>

<p>
また、BEP用スピーチサーバパッケージに含まれる
英語カタカナ読み辞書(英単語に対応する発音をカタカナで表記してある辞書)の<code>bep-eng.dic</code>を
<code>/usr/local/lib/dtalker</code>にコピーする。
この英語カタカナ読み辞書については、環境変数<code>BEP_DIC_PATH</code>
でファイルのフルパスを指定することで変更することもできる。
</p>

<h4>5.1.2 英語TTSエンジンのインストール</h4>

<p><a href="http://www.software.ibm.com/speech/dev">IBMのサイト</a>から、
ランタイムライブラリ(ViaVoice_Outloud_rtk-5.1-1.2.i386.rpm)及び開発キット
(ViaVoice_Outloud_sdk-5.1-1.2.i386.rpm)を取得する。(いずれも無料)</p>

<p>ViaVoice OutloudのRTK及びSDKをRPMから適当な方法でインストール
する。Red Hat(6.2, 7.x)では以下のコマンドでインストールできる。
（Red Hat系以外のディストリビューションでは特別な作業が必要になる。）</p>

<pre>
# rpm -ivh ViaVoice_TTS_rtk-5.1-1.2.i386.rpm
# rpm -ivh ViaVoice_TTS_sdk-5.1-1.2.i386.rpm
</pre>

<p>
rpmは<code>/etc/profile</code>に環境変数を設定するので、これを
有効にするため、シェルを起動し直すか再ログインする。
</p>

<h4>5.1.3 Linux用スピーチサーバのインストール</h4>

<p>Makefileの必要個所、主にインストールprefixの確認とデバッ
グオプションの選択、を適宜修正する。</p>

<p>以下のコマンドでプログラムを作製し、システムにインストールする。</p>

<pre>
$ make
$ make install
</pre>

<h4>5.1.4 BEPパッケージのインストール方法</h4>

<p>！！！！！！！！！！！！！</p>
<p>おそらくbep-raman-diffのREADME-ja.txtを使う。</p>


<h3><a name="52WinInstall">5.2 Windows版BEPのインストール方法</a></h3>

<p>Windows版のインストール手順は大きく分けて二つのプロセスになる。日本語と
英語のTTSエンジンのインストール、BEPのWindows版パッケージのインストール
である。それぞれについて解説する。</p>

<h4>5.2.1 Microsoft Speech APIのインストール</h4>

<p>Microsoftのサイトから<a
href="http://activex.microsoft.com/activex/controls/sapi/spchapi.exe">spchapi.exe</a>
をダウンロードし実行すると、自動的に必要なファイルがシステムにインストー
ルされる。システムの状況によってはシステムの再起動が必要な場合がある。
</p>

<h4>5.2.2 日本語TTSエンジンのインストール</h4>

<p>Windows版(1)は、日本語音声合成ライブラリ(TTSエンジン)として、IBMの商品である 
ProTalker 97 (定価9800円)を使用する。Protalker 97 は、音声合成だけの単体の商品として
パソコンショップで購入できる。</p>

<p>Windows版(2)は東芝LaLaVoiceを使用するが、これも製品としてパソコンショップなど
で購入できる。（音声認識機能やアプリケーション込みのパッケージ「LaLaVoice 2001」の定価は16000円。
東芝のパソコンにはプレインストールされている。）
</p>

<h4>5.2.3 英語TTSエンジンのインストール</h4>

<p>Microsoftのサイトから
<a href="http://download.microsoft.com/msdownload/sapi/4.0/rtw/4.0a/en/msttsL.EXE">
msttsL.exe</a>をダウンロードし、実行する。システムの指示に従ってインストールを行えばよい。
</p>

<h4>5.2.4 Bilingual Emacspeak組み込み済みMeadowのインストール</h4>

<p><a href="ftp://ftp.m17n.org/pub/bep/win32/release/bepw01.exe">BEP
のパッケージ</a>をダウンロードする。</p>
<p>ダウンロードしたファイルをExplorerなどで実行し、指示に従ってインストー
ルすればよい。</p>


<p><a href="#TOC">[目次に戻る]</a></p>

<h2><a name="6Operation">6. 操作仕様</a></h2>

<p>BEPの簡単な操作方法、バイリンガルの使い方、音声を使ったEmacsアプリケー
ションの簡単な使い方について述べる。</p>

<h3><a name="61Engage">6.1 BEPの起動方法</a></h3>

<p>Emacs(Meadow)を起動すると、自動的に音声が出力して、BEPが使える状態に
なる。この後は総ての操作が音声化される。</p>

<h3><a name="62Voicify">6.2 基本的な読み上げコマンド</a></h3>

<p>Emacspeakには豊富な読み上げコマンドが存在する。BEPでもその総てを使用
することができる。ここでは基本的な読み上げコマンドを紹介する。</p>

<dl>
 <dt>カーソルキーによる行・カラムの読み上げ
 <dd><p>カーソルキーを動かすことにより、ポイントされた文字・行を読み上げ
る</p>
 <dt>音声の停止: C-e s
 <dd><p>読み上げ中の音声を即時停止する</p>
 <dt>音声速度の設定: C-e 0 -- C-e 9
 <dd><p>読み上げスピードを切り替える。</p>
 <dt>１行読み上げ: C-e l
 <dd><p>カーソルがある行を総て読み上げる</p>
 <dt>カーソル以降の読み上げ: C-e n
 <dd><p>カーソルより後の内容を総て読み上げる</p>
 <dt>バッファの読み上げ: C-e b
 <dd><p>編集中のバッファの内容を総て読み上げる</p>
 <dt>モードラインの読み上げ: C-e m
 <dd><p>バッファに対応するモードラインを読み上げる</p>
 <dt>現在行数の読み上げ: C-e C-l
 <dd><p>編集中のバッファの現在行数を読み上げる</p>
</dl>

<h3><a name="63Lang">6.3 言語切り替えなどのコマンド</a></h3>

<p><a href="#42Bilingual">4.2節「ELisp部バイリンガル化機能の概要」</a>でも述べた
ように、(Linux版)BEPは、ユーザのニーズに応じてバイリンガルのモードを切り替えるこ
とができる。これはより音声を聞きやすくするために重要な機能である。</p>

<dl>
 <dt>バイリンガルモードの切り替え: C-e x m s
 <dd><p>読み上げの方式を変更する。ASCII文字は総てネイティブ発音、ある一
     定以上の長さの文字列はネイティブ発音、総てカタカナ英語(日本語発音の英語)の
     3通りを切り替えることができる。</p>
</dl>

<h3><a name="64Applications">6.4 Emacsアプリケーションの音声利用例</a></h3>

<p>Emacsで利用されるいくつかのアプリケーションを取り上げながら、BEPの動
作を述べる。</p>

<h4>プログラミング編集</h4>

<p>Emacspeakでは、font-lockに相当する効果をを音声で表現するために、
voice-lockという概念を導入している。Lisp, C, C++, Perlなどのソースファイ
ルを読み込んで、バッファを音声出力させてみよう。</p>

<p>キーワード・文字列・コメントなどによって、声が変化することがわかる。
音声利用の場合でも十分にプログラム構造を理解することができる。</p>

<h4>カレンダー・モード</h4>

<p>Emacspeakは、カレンダーのように2次元の表として意味を持つ情報を、1次元の音声
情報でもわかりやすいようにユーザに提示する。</p>

<p>カレンダーモードを起動すると、&quot;Welcome to the calendar&quot;という音声が聞
こえて、カレンダーが表示される。</p>

<p>今日の情報を聞きたいときは C-e m とタイプする。&quot;Monday, Feb 11, 2002&quot;と
聞こえるだろう。カーソルキーで日付を変えていくと、必要な情報を取得して音
声で聞いたときに意味のある情報に組み立て直しているのがわかる。</p>

<h4>電子メール Mew</h4>

<p>Mewを音声で利用するときに必要になる音声ガイドを出力するパッケージを新
たに開発した。引用文では声が変化したり、削除マークをつけたメールは
声が変化するような工夫がされている。</p>

<dl>
 <dt>Summary-mode
 <dd><p>メールのリストが表示されているところでは、削除マーク・レビューマー
     クなどのマークの種類によって声を変えることで、ユーザにこのメールがど
     のようなメールかを伝えている。</p>
 <dt>メッセージの読み上げ
 <dd><p>一覧から読み上げたいメールを選択して、&quot;.&quot;のキーを入力すると、自
     動的にメッセージを読み上げる。このときに、引用文は声を変化させて、
     それとわかるように工夫している。</p>
</dl>


<p><a href="#TOC">[目次に戻る]</a></p>

<h2><a name="7Examine">7. テスト及び診断方法</a></h2>

<p>
BEPのELisp部及びLinuxスピーチサーバの動作確認、診断方法について述べる。
</p>

<h3><a name="71LinuxSS">7.1 Linuxスピーチサーバ</a></h3>

<h4>7.1.1 スピーチサーバのテスト</h4>

<p>
BEPを動作させるためには、まずスピーチサーバが正常に動作している必要があ
る。スピーチサーバは標準入力からコマンドを１行単位で読み、コマンドを解釈
して動作するプログラムなので、シェル上から起動してコマンドを入力すること
で簡単に動作確認できる。
</p>

<p>
Linuxスピーチサーバを起動するには、LinuxSpeechServerのディレクトリに移動
し、<code>./bep-ss</code>を起動する。以下のような出力があれば正常に起動
されたことが確認できる。
</p>

<pre>
DT: Initializing CreateSystem speech engine...
TTS_Outloud: IBM Viavoice outloud speech synth...
Bilingual Emacspeak Speech Server Ver. 2.0 started!
ready
</pre>

<p>
動作を確認するには、一行単位で以下のように入力する。
</p>

<pre>
q {Hello in Japanese}
tts_set_language en
q {Hello in English}
tts_set_language ja
q {Hello in Japanese again}
d
</pre>

<p>
<code>d</code>を入力して改行を入力すると日本語と英語で交互に読み上げ
が行われるはずである。また、読み上げている途中で<code>s</code>を入力後改
行を入力すると、その時点で発声が停止する。
</p>

<p>
<code>ready</code>のメッセージが出力されずに<code>bep-ss</code>が終了す
る場合、初期設定に問題があることが考えられる。その例のいくつかを示す。
</p>

<dl>
<dt>DT: can not load Eng to Kana dictionary: /usr/wrong/path/bep-eng.dic</dt>
<dd>カタカナ英語読み上げに必要なbep-eng.dicが見つからない場合のエラーで
    ある。環境変数<code>BEP_DIC_PATH</code>で<code>bep-eng.dic</code>の
    フルパスを指定するか、ファイルを<code>config.h</code>で指定された場
    所に配置する。</dd>
<dt>DT: SYT_syntheInit failed</dt>
<dd>日本語音声合成のための波形処理を初期化できなかった。主な原因としては
    Linux用日本語音声合成ライブラリのための波形辞書
    <code>HIGH11.VSD</code>を<code>config.h</code>で指定した場所に配置し
    ていないことが考えられる。辞書のインストール状況を確認する必要がある。
    </dd>
<dt>DT: LNG_analyzeInit failed</dt>
<dd>同じく日本語音声合成の言語処理部が初期化できなかったことを示している。
    主な原因としては言語処理のための辞書<code>wd2k03.dic</code>がロード
    できなかったことが考えられる。<code>config.h</code>による指定と辞書
    のインストール状況を確認する必要がある。</dd>
<dt>Outloud: Create ECI handle failed</dt>
<dd>Outloud TTSが初期化できなかった場合のエラーである。いろいろな原因が
    考えられるが、もっとも可能性が高いのは<code>eci.ini</code>ファイルが
    見つからなかった場合である。標準的なViaVoice OutloudのRPMからのイン
    ストールでは、ecil.iniは
<code>/usr/lib/ViaVoiceTTS/eci.ini</code>
に作成される。また、このファイルは<code>inigen</code>プログラムを利用し
て、
<pre>
/usr/lib/ViaVoiceTTS/bin/inigen /usr/lib/libibmeci50.so eci.ini
</pre>
として作成することができる。
詳細はViaVoice Outloud RTK付属のドキュメントを参照されたい。
</dd>
<dt>ライブラリがロードできない場合</dt>
<dd>標準的なライブラリパス(<code>/usr/lib</code>等)に必要なTTSソフトウェ
    アのライブラリ群がコピーされ、ldconfigされているかを確認する。または、
    <code>LD_LIBRARY_PATH</code>環境変数が共有ライブラリを配置した場所に
    適切に設定されているかを確認する。</dd>
<dt>音がでない</dt>
<dd>コマンドは受け付けられて音がでない場合、サウンドデバイスが利用可能な
    状態になっているか確認する。多くのサウンドチップでは他の音声を再生す
    るプログラムが動作していると音を出すことができない。本ソフトウェアは
    esound等のサウンドシステムには特に対応していない。</dd>
</dl>

<h4>7.1.2 デバッグ情報の収集</h4>

<p>
上記のような情報で解決できない問題、正常動作中に発生するスレッド同期やコ
マンド処理に伴う問題を診断するために、デバッグ用バイナリを作成することが
できる。<code>Makefile</code>内でデバッグ用コンパイルオプションを有効に
し、</p>

<pre>
make clean; make
</pre>

<p>
を行うことで作成される。
</p>

<p>
デバッグ版では標準出力に処理に伴ってデバッグ出力が行われる他、
<code>HOME</code>ディレクトリの<code>elog</code>ファイルにデバッグ情報が
書き込まれる。
</p>

<p>
また、以下のように操作すると、バッファ<code> *speaker*</code>(最初はスペー
ス)にスピーチサーバの標準出力の内容が得られる。
</p>

<pre>
M-x dtk-toggle-debug RET
C-e C-s
</pre>

<p>
<code>elog</code>に出力されるメッセージは、入力を示す<code>Input:</code>
やモジュール名で始まる文字列である。開発の進行に伴って変更されるためここ
での詳説は割愛するが、ユーザによる問題の特定、開発グループでの問題解決に
役立つ情報となるはずである。逆に、ログファイルは大きくなるため、必要のな
い場合にはデバッグ出力を行わない最適化版バイナリを作成して利用する方がよ
い。
</p>

<h3><a name="72BEPExamine">7.2 BEPの動作テスト</a></h3>

<h4>7.2.1 バイリンガル動作のテスト</h4>

<p>BEPのバイリンガル機能について、テスト方法の例を示す。
バイリンガルで音声出力することを確認するもっとも簡単な方法は適当な内
容のファイルを作成してみることである。
たとえばC-x C-fで新規にファイルを作成し、以下のように入力する。
</p>

<pre>
This is Bilingual Emacspeak(BEP).
これはBEPです。
</pre>

<p>
デフォルトの状態では１行目の英文字列もカタカナ英語で読み上げられる。上下
のカーソルキーやC-n C-pを使って行移動すると、移動先の行が読み上げられる。
</p>

<p>
次に２行目として以下のように挿入してみる。
</p>

<pre>
This is Bilingual Emacspeak(BEP).
It talks Japanese and English fluently.
これはBEPです。
</pre>

<p>
上記の行を入力していくと、途中からキー入力が英語発音で行われるようになる。
その段階で上下のカーソル移動を行うと、１行目も英語で発音されるようになっ
ていることが分かる。
また、ここで２行目を削除すると、再び１行目はカタカナ英語で発音される。
</p>

<p>
カタカナ英語のときには「()」は「カッコ」及び「カッコトジ」と読まれ、英語
発音では「left paren」、「right paren」と読むようになる。
</p>

<p>
次に<code>C-e x m s </code>(言語属性付与方式のトグル)を何度か行って上記
の文章がどのように読まれるか確認すると、少しずつ読み方が変化することが分
かる。
<code>emacspeak-m17n-put-language-ja-ne</code>では最後の行の「BEP」を含
め、英文字列はすべて英語発音となる。
<code>emacspeak-m17n-put-language-ja-ke-a</code>はデフォルトの動作である。
<code>emacspeak-m17n-put-language-ja-ke-all</code>では英語文字列もすべて
カタカナ英語として読み上げられる。
</p>

<h4>7.2.2 基礎的なトラブル対処方法</h4>

<p>
BEPを使い始める時に一度は経験するのが、Emacsを起動して直後からminibuffer
に「process speaker not running」というメッセージが出力され、どのような
操作をしても回避できないという状態である。このような時は他のシェルから
Emacsをkillするか、強引に <code>M-x kill-emacs RET</code>とタイプして終
了させるしかない。
</p>

<p>
これは文字どおり、スピーチサーバが起動できなかったか、起動してもすぐに終
了してしまったかのいずれかの原因で起きる。
このような場合の対処方法は、一度戻ってスピーチサーバが単体で動作すること
を確かめることである。シェルからスピーチサーバを起動し、7.1で述べた方法
で正常に動作するように設定する。
</p>

<p>
もう一つ考えられる問題点は、EmacsからBEPを起動するときの環境変数の指定で
ある。BEPはスピーチサーバを起動するとき、環境変数<code>DTK_TCL</code>に
指定されたプログラムに<code>DTK_PROGRAM</code>の引数を渡して起動する。
BEPの場合はスピーチサーバの動作にtclXを必要としないため、
<code>DTK_TCL</code>にスピーチサーバの実行ファイル名を指定して起動する。
または、lisp変数の<code>dtk-tcl</code>, <code>dtk-program</code>に直接値
を設定することもできる。
</p>

<p><a href="#TOC">[目次に戻る]</a></p>

<h2><a name="8OpenSource">8. オープンソースによる福祉システム開発について</a></h2>

<h3><a name="81Bazzar">8.1 バザール型福祉システム開発の重要性</a></h3>

<p>福祉の市場は、(1) ユーザ数が少ない、(2) ユーザのニーズが多様で特殊である、(3) 開発
者が障害者のニーズを正確に把握するのが難しい、という特徴を持つ。そのため一般的な
商品開発のプロセスで対応すると非常に高価な製品になってしまったり、障害者のニーズ
とずれた製品が市場に出てしまったりすることが多い。</p>

<p>オープンソースの世界で用いられるバザール型の開発手法は、このような特徴を持つ
福祉市場に対応した製品を出す新しい開発手法になるかもしれない。なぜならば、(1) ソ
フトウェアはコピーが容易なので製品の数の多少は関係しない、(2) ユーザ自身が開発
を行う又は開発者に近い立場で開発にコミットすることでユーザのニーズを的確・確実に
開発に反映させることができる、(3) 開発がオープンになりユーザの意見が早いサイクル
で取り入れられやすい、(4) 利益を上げることが最優先事項にならないので製品の質にこ
だわることが可能である、からである。</p>

<p>オープンソースは魔法の杖ではないので、何でもオープンソースで開発すればうまく
いくわけではない。特に大事なのは、(1) 開発者が強い開発動機を持っていること、(2) 
実際に動くシステムをユーザコミュニティに提供できること、(3) 開発者が必要なリソース(ス
キル、時間、金銭的余裕など)を持っていること、である。福祉システム開発にバザール
型の開発を適用するに当たっては、強い動機を持った、つまり自分でそれを使いたいと思っ
ている開発者がいることが重要になる。それがかなわない場合でも、実際にそのシステム
を使いたいと思っている人間がコア開発者と密接に連絡を取れるようになっていることが
大事である。</p>

<p>本プロジェクトは、GNU/LinuxやGNU EmacsやオープンソースのEmacspeakをベースにし
た、バザール型の音声システム開発である。本提案が目指しているのは、音声出力利用の
エキスパートである視覚障害者の経験や要求を満たすような音声出力インターフェースを
実現することである。本提案は晴眼者と協力しながら視覚障害者が中心となって開発して
いるシステムであり、オープンソースの利点を生かしてユーザが本当に必要とするシステ
ムを作り上げることを目指している。</p>

<h3><a name="82BEPBazzar">8.2 BEPにおけるバザール型開発の実際</a></h3>

<p>BEPの開発は、視覚障害者と晴眼者の共同プロジェクトで実施された。中心的な開発者
は全盲の視覚障害者であり、晴眼者1名と視覚障害者3名でほとんどの部分を開発した。こ
のほかに晴眼者約2名と視覚障害者約2名が毎月のオフライン開発者ミーティングに参加し
て開発の方針やシステムの仕様決定に参加した。BEPには2種類のメーリグリストがあり、
ユーザ用のメーリングリストである bep@argv.org は参加者数67名で、開設以来1年半で
7000通の投稿がある。開発者用のメーリングリストである bep-dev@arg.org を開設した
のは約半年前であるが、参加者数は19名で、既に1000通を超えるメールが投稿されている。
BEPのWebサイトを開設したのは約1年前であるが、BEPのトップページは約5500 ビュー、
Windows版BEPのページは約3400ビュー、Linux版BEPのページは約1000ビューに到達してい
る。このメーリングリストやWebサイトを通じてユーザテストやユーザサポートを行って
いる。BEPの場合、開発メンバーのほとんどが視覚障害者であるので、視覚障害者である
ユーザに適した情報提供ができていると思う。</p>

<p>メーリングリストの投稿数やWebサイトのアクセス数とBEPの発展の間に関連が見られ
るので、<a href="#103ML_WebAccess">10.3節「BEPメーリングリストやWebアクセスの資
料」</a>で詳しく述べる。</p>

<p>ユーザの意見やバグ報告をすぐに反映しやすいのがオープンソースの利点であるが、
Windows版の開発においては開発者に余裕がないために修正が大幅に遅れるという問題も
生じている。BEP全体でも開発者が少ないために、少数の人間に大きな負荷がかかるとい
う問題を解消することができずにいる。WindowsのVisual C++を使ってMFCのアプリケーショ
ンを書けるプログラマーはたくさんいるが、BEPの開発に参加しようというプログラマー
は少ない。LinuxでのC++での開発でも同様のことが言える。ドキュメント作成などに関し
てもなかなか協力者を集められない。BEPでは、開発しながらBEPが備えるべき機能を議論
していった、つまり走りながら考えたので、仕様を完全に決めて外注するという開発形態
をとることは難しく、結局2,3人が議論しながら開発するしかなかった。開発のコアメン
バーが足りないとことがBEPの大きな問題である。</P>

<p><a href="#TOC">[目次に戻る]</a></p>

<h2><a name="9Conclusion">9. まとめ</a></h2>

<h3><a name="91Results">9.1 開発成果</a></h3>

<p>本開発プロジェクトの成果を開発項目ごとにまとめる。本開発プロジェクトの中心課
題であるLinuxのバイリンガル音声化システムに関しては、予定通り完成することができ
た。</p>

<dl>
  <dt>スピーチサーバの改良；
  <dd>Linux版スピーチサーバは、IBMの英語音声合成ライブラリとクリエートシステムの日
本語音声合成ライブラリに対応し、(1) 日本語と英語の音声合成エンジンの切り変え、
(2) ジャパニーズ英語とネイティブ発音の2種類の発音の切り替え、をスピーチサーバへ
のコマンドにより自由に制御できるスピーチサーバが完成した。<br>

Windows版スピーチサーバは、以下2種類のスピーチサーバを作った。Linux版と同等の機
能を持つものは開発継続中。

	(1) IBMの日本語音声合成ライブラリに対応し、日本語とネイティブ発音の英語をス
ピーチサーバで自動切換えするスピーチサーバ、
	(2) 東芝の日本語音声合成ライブラリに対応し、日本語とカタカナ英語をスピーチサーバで
自動切換えするスピーチサーバ。

  <dt>Emacs Lisp部の改良
  <dd>本システムの基盤となっているEmacspeakのEmacs Lisp部を拡張し、日本語音声化
に必要な機能を実装し、3種類のバイリンガルモードを使い分けられるように拡張した。
当開発プロジェクトの成果を本家Emacspeakに取り込む作業にも取り掛かった。

  <dt>システム全体の2ヶ国語対応
  <dd>Linux版BEPは今年度中に一般公開する。
今回の言語切り替え機能に対応したWindows版BEPも、一般公開に向けて開発を継続する予定。

  <dt>視覚障害者用インストーラの作成
  <dd>Linux版はMakefileを使ったインストーラを今年度中に一般公開する。
Windows版は(1)のバージョンの簡単インストーラを既に一般公開している。

  <dt>ユーザテスト
  <dd>Windows版は、(1)のバージョンを日常的にBEPメンバーが使っている。(2)のバージョ
ンも開発メンバー数人が使用している。BEPメーリングリストで意見を述べてもらってい
る。Linux版はまだ開発メンバー数人が使用しているだけである。

  <dt>ユーザサポート
	<dd>BEPのWebサイト及びBEPメーリングリストでユーザサポートを実施した。<a
href="#103ML_WebAccess">資料編 10.3章</a>に書いたように、メーリングリストでは活
発な意見交換や情報交換が行われている。

</dl>


<h3><a name="92Prospects">9.2 今後の課題</a></h3>

<p>今回の開発でIPAの申請書に書いた中核部分は完成させることができたが、実際にユー
ザに使ってもらうためにはまだまだ改良が必要である。バイリンガル化に関して言えばま
だ拡張が不完全なところがあり、Windows版のスピーチサーバがまだ今回の拡張に対応で
きていない。本家Emacspeakへのコードの還元もこれからの課題である。また我々が使用
している商用の日本語音声合成ライブラリーにも機能が不十分な部分があり、外部の資金
を投入して改善をお願いしている。</p>

<p>Emacsは一般ユーザになじみがないアプリケーションであり、Linux自身も一般には普
及していないので、BEPに関心があっても使い始めることが出来ないユーザも存在する。
BEPを単なるソフトウェアを超えたひとつのシステムと見た場合、このようなユーザの教
育やサポートも今後の大きな課題である。</p>

<p>今回Linux版のBEPが動くようになったので、これを組み込みLinuxに応用できないかと
考えている。つまり、最近はi-modeやPDAなどの携帯情報機器の重要性が増しているので、
これらの機器を視覚障害者も利用できるようにしておく必要があり、iPAQやLinux版
ZaurusなどにBEPを組み込んで、視覚障害者も使える携帯情報機器を実現できないか検討
している。</p>

<p>BEPの開発の中心メンバーは企業や大学などに所属しており、所属組織が個人での活動
をあまり認めなかったために組織の身分と個人の身分を分離することが難しく、IPAから
の委託開発と所属組織の仕事との両立にかなりの困難を生じた。</p>

<h3><a name="93ourTTS">9.3 音声合成への要望</a></h3>

<p>本システムを使用するとき、音声合成ライブラリだけがオープンソースなソフトウェ
アを使用できない。英語の音声合成ライブラリはWindows用もLinux用も無料で配布されて
いるものがあるが、日本語に関しては両OSともメーカの製品を購入しなければならない。
視覚障害者が音声でコンピュータを利用する際、音声の機能や品質は極めて重要な要素で
あるが、彼らの要求を満たすものはメーカが開発した商品以外にはない。IPAなどの資金
を得てソースのライセンスを購入するなどの方法で、商用品質の日本語音声合成ライブラ
リをオープンドメインに置けないものかと考えている。</p>

<p>視覚障害者が使用する音声合成は倍速以上の高速で音声化しても聞きやすい声を持ち、
しかも応答性がよいなどの機能が必要である。しかし現在の音声合成の研究開発は、「重
くてもよいから人間のように自然に発話する」ことに主眼が置かれ、視覚障害者のニーズ
を満たせていない。</p>


<p><a href="#TOC">[目次に戻る]</a></p>

<h2><a name="10Data">10. 資料</a></h2>

<h3><a name="101Ref">10.1 開発成果の主な発表論文類</a></h3>

<ul>
  <li>T. Watanabe, K. Inoue, M. Sakamoto, M. Kiriake, H. Honda, T. Nishimoto,
and T. Kamae: Bilingual Emacspeak Platform - A universal speech interface with
GNU Emacs -, Universal Access in HCI (Lawrence Erlbaum Associates, ed. by
C. Stephandis), Vol. 3 of the Proceedings of HCI International 2001, pp.446-449.

  <li>T. Watanabe, K. Inoue, M. Sakamoto, and M. Kiriake: BEP: a practical
bilingual speech synthesis system for Japanese, Proceedings of Pacific
Association for Computational Linguistics 2001, pp.307-314.

  <li>渡辺隆行、切明政憲: 日本人用の日米2ヶ国語高機能音声化システム BEP, 情報処
理学会 音声言語情報処理研究会 (2001年10月19日、東京)、情処技報 Vol.2001/100,
pp.1-8.

  <li>渡辺隆行、井上浩一、切明政憲: 日米2ヶ国語Emacs音声化システムBEPとLinuxアク
セシビリティ向上, IPA未踏ソフトウェア創造事業シンポジウム (2001年11月21日、京都).

  <li>渡辺隆行: 日本人(視覚障害者)用の日英2ヶ国語音声化システムBEP, 第45回ロービ
ジョン研究会 (2002年1月12日、東京女子大学).
</ul>

<h3><a name="102Pronunciations">10.2 カタカナ発音とネイティブ発音を必要とする理由</a></h3>

<p>BEPのユーザ9名に、BEPを使う際にカタカナ英語（以下、K英語と略す）とネイティブ
英語（N英語）をどう使い分けたいかインタビューした。9名の内訳は男性8名と女性1名、
全盲5名と弱視1名と晴眼3名である。英語の聞き取り能力に関してはほぼ不自由なく聞き
取れるユーザから英語が苦手なユーザまでさまざまである。インタビューの結果、以下の
ことが明らかになった。</p>

<ul>
 <li>英語の聞き取り能力が高いユーザほどN英語を好む。
 <li>N英語には、イントネーションやアクセントが自然であるという利点と、K英語では
区別できない`right'と`light'、`bat'と`but'のような子音や母音を区別できるという利
点がある。
 <li>K英語を使うと、もともとカタカナで書かれていたのか、それとも音声化システム
がもともとの英語をK英語に変換したのかわからなくなる。N英語の場合、その情報が英語
で書かれていることがわかる。
 <li>英語で書かれている情報はN英語で聞きたいという要求がある。したがって、N英語
で発音する機能が絶対に必要である。
 <li>Webを読むときなどに、日本語とN英語を自動的に切り替えて音声化するシステムを
必要としているユーザがいる。
 <li>N英語とK英語のどちらを使いたいかは、それぞれの合成音声の品質によっても変化
する。つまり、聞きやすい声であることの方が重要である。
 <li> どちらに慣れているかにも影響される。
 <li>一般に日本人の英語聞き取り能力は日本語聞き取り能力より劣るので、N英語で読
み上げる場合、日本語よりも速度を遅くした方がよい。
 <li>十分な英語の聞き取り能力を持っていない場合、いきなりN英語で読み上げられる
と何を言っているのか聞き取れない。したがって、短い単位で日本語と英語が切り替わる
場合はK英語で発音した方がよい。その意味でメニューやシステムメッセージなどはK英語
の方がよい。
 <li>情報の長さが長いほどK英語よりN英語が適するようになる。
 <li>日本人ならばK英語で読み上げても聞き取れる。
 <li>ある程度英語で議論できる程度の聞き取り能力を持ったユーザでも、仕事で読まな
ければならない科学技術文献は、正確に理解するためにK英語か点字を使いたいという要
求がある。
 <li>逆に文系の文書はN英語の方が適する。
</ul>

<p>BEPのバイリンガル化にあたっては、以上の点を考慮して3種類のモード（ネイティブ
英語、カタカナ英語、両者の混在）を用意した。</p>

<h3><a name="103ML_WebAccess">10.3 BEPメーリングリストやWebアクセスの統計データ</a></h3>

<p>BEPもメーリングリストの投稿数やWebのアクセスカウンタの記録を見ると、BEPの活動
がよくわかるので、2002年1月までの統計を<a name="Fig23">下図2,3</a>に示す。</p>

<p class="center"><img src="BEP_ML.png" width="518" height="343" alt="グラフの詳
細は「説明」リンクを参照"><br>
図2. メーリングリストの月別投稿数 <a href="BEP_Figs.html">(説明)</a></p>

<p class="center"><img src="BEP_Webaccess.png" width="518" height="339" alt="グ
ラフの詳細は「説明」リンクを参照"><br> 図3. Webサイトのアクセスカウンタの月別増
加数 <a href="BEP_Figs.html">(説明)</a><br>
*; Webアクセスカウントは月末に集計。ただし2001年4月は14日に集計。</p>

<p>メーリングリストが2000年8月ごろ盛んになったのは、この時期にバイリンガルでしゃ
べるWindows版のスピーチサーバが動くようになって、はじめてBEPがある程度まともに動
くようになったからである。Linux版は2000年11月末のLinux Conferenceでの発表にあわ
せて開発を進め、同年末に日本語とカタカナ英語をなんとかしゃべるようになった。また
2001年1月にはWebサイトを作り、Windows版とLinux版のBEPをオープンソースとして一般
公開した。同時期にWindows版を障害者用のメーリングリストで案内したり、Linux
magagineの佐々木氏の記事で取り上げてもらったりしたので、メーリングリストも活発に
なっている。メーリングリストとWebともに2001年5月に活発になっている理由は今のところ
特に思い当たらないが、IPAに応募することになって盛り上がったのが原因かもしれない。
メーリングリストが2001年10月に投稿数が減っているように見えるのはユーザ用のBEPと
開発者用のBEP-devに分けたからである。2001年4月のWebアクセス数が減っているように
見えるのは、集計が4月14日と他の月より半月早かったためである。2001年1月にWebアク
セスが多いのは、Webサイトの製作者側のアクセス頻度が高かったことも大いに影響して
いる。</p>

<p><a href="#TOC">[目次に戻る]</a></p>

<hr>
<p>Copyright 2002 <a href="http://www.argv.org/bep/">Bilingual Emacspeak Project</a></p>
<!-- hhmts start --> Last modified: Wed Feb 13 15:04:50 JST 2002 <!-- hhmts end -->
</body>
</html>






