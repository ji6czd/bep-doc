<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html lang="ja">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=iso-2022-jp">
	<link rev="made" href="mailto:takayuki@la.shonan-it.ac.jp">
	<meta name="author" content="Takayuki Watanabe">
	<meta name="keywords" content="IPA, BEP">
	<link rel="stylesheet" type="text/css" href="http://www.sfc.keio.ac.jp/~wata7be/report.css">
	<title>BEP 未踏ソフト成果報告書</title>
</head>

<body>
<!-- $Id: FinalReport.html,v 1.14 2002/02/10 09:29:46 inoue Exp $
-->

<h1>「日米2ヶ国語Emacs音声化システムBEPによるLinuxの音声利用」<br>成果報告書</h1>

<p>2002年2月15日</p>
<p>渡辺隆行、切明政憲</p>

<h2>1. プロジェクトの目的及び概要</h2>

<h3>1.1 開発の背景</h3>

<p>MS-DOSは文字でコマンドを入力し文字で情報が出力されるOSであったので視覚障害者にも
使いやすいOSであった．1990年代に入ると初心者にも使いやすいGUI (Graphical User
Interface)を持ったWindowsが登場した．Windowsは最新の技術がいち早く導入される反面，
ウインドウ・アイコン・メニュー・ポインタなどのGUI部品による操作を前提にしている
場合が多いので，Windows標準の部品を使ったりスクリーンリーダに配慮して作成したり
しないと視覚障害者が使えないアプリケーションになってしまう．またバージョンアップ
の周期が早い巨大なOSに合わせてスクリーンリーダを開発するのは困難な作業である．そ
のため，Windows はなじみにくいとか使いにくいとか感じる人がいたり，新しいバージョ
ンでは使えない機能が生じたりする．実際、Windowsでなくてもできる作業ならばMS-DOSを使
うユーザも存在する．</p>

<p>Windows以外の高機能なOSとして，LinuxなどのUNIX系OSが注目を集めている．UNIXは
もともとテキストコンソールから操作するOSであり，文字情報だけでOSを管理できる．X
Window SystemなどのGUIはテキストの世界の上に別のレイヤとして存在しているだけで，
ユーザは好みに応じてテキストツールでもGUIツールでもUNIXを利用できる．したがって，
UNIXもMS-DOSと同じように音声利用できてMS-DOSを利用している視覚障害者が移行しやすいOSで
あるはずであるが，ユーザが少ないこともあってUNIX用のスクリーンリーダは数少なく，
日本語スクリーンリーダで実用化されているものがない．</p>

<p>つまり，視覚障害者にとってMS-DOSはOSとしての機能が低く新たに習得しても報われない，
WindowsのGUIは音声化システムに本質的に適していない，UNIXには音声化システムがほと
んどないといった状態になっており，最新コンピュータの機能を活用できる使いやすい日
本語音声化システムが待望されている．</p>

<p>職場での仕事には正確さと速度を求められるので，仕事で使う音声化システムは情報
を効率よく正確に音声化しなければならない．しかし既存の視覚障害者用音声化システム
は必ずしもこのような要求を満たしていない．また仕事や勉学の場で出会う情報は日本語
と英語が混在している場合が多い．ところが既存の音声化システムは日本語用に設計され
ているため英語を正しく音声化することが苦手であり，ローマ字を正しく読めるシステム
も少ない．したがって，ローマ字や日英2ヶ国語が混在した情報を正確に又わかりやすく
音声化できるシステムも必要とされている．</p>

<h3>1.2 オープンプロジェクトBEP</h3>

<p>そこで我々はこのような視覚障害者の要求を満たす音声化システムを開発するために、
1999年に晴眼者と視覚障害者が個人資格で集まったオープンソースのプロジェクトを立ち
上げ、日米二ヶ国語のEmacs音声化システムBEP(Bilingual Emacspeak Platform)の開発に
取り組んだ。

<p>BEPはRaman博士が開発した<a
href="http://emacspeak.sourceforge.net/">Emacspeak</a>を基にしており、既存の日本
語音声化システムと比較して以下の特徴を持つ。</p>

<OL>
 <li>GUIに対するAUI(聴覚専用UI)を持ち、聴覚に最適化して情報を提供できる。
 <li>Emacsが扱う多言語情報を各言語のテキスト音声合成エンジンで出力する事を目指す。
 <li>バザール型の開発であり、視覚障害者自身が開発の中心にいてユーザが本当に必要
とする機能を実装している。また成果をオープンソースとして公開している。
 <li>WindowsでもLinuxでも、同じ操作性でEmacsを音声出力で利用できる。
</ol>

<h3>1.3 本プロジェクト開発の目的</h3>

<p>BEPは2001年1月にアルファ版を公開したが、視覚障害者に利用してもらうためにはま
だまだ多くの改良が必要である。そこで本開発では、Linux版/Windows版スピーチサーバ
の改良、Emacs Lisp部の改良、スピーチサーバ及びBEP Emacs Lisp部の多言語化、視覚障
害者用インストーラの作成、ユーザテストとユーザサポートなどに取り組んだ。</p>


<h2>2. 全体構成</h2>

<p>図1に示すように，BEPはEmacspeakをバイリンガルに拡張したEmacs Lisp部と，日本語
と英語の音声合成エンジンを制御するスピーチサーバ部の2つに分かれる．Emacs Lisp部
は両OSで共通しているが，スピーチサーバはOSごとに異なる．音声合成ライブラリは市販
の製品を用いる。図中、太線枠部が今回開発した部分。</p>

<p><img src="BEP_config.png" alt="Windows版とLinux版の構成図。BEPはElisp部とスピーチサーバ部
に分かれている。"><br>
図1. BEP構成図</p>


<h2>3. 動作確認環境</h2>

<p>本システムはWindowsでもLinuxでも使えるEmacsの音声化システムであり、今回開発し
た部分(Emacs Lispライブラリ、各OS用のスピーチサーバ)以外に、Emacsと日本語と英語
の音声合成ライブラリが必要である。以下の環境で動作を確認している。</p>

<h3>3.1 Linux版BEP</h3>

<ul>
 <li>CPU: Pentium MMX 266MHz 以上
 <li>Memory: 128MB 以上
 <li>必要なハードディスク容量: 20MB程度
</ul>

<p>以下のソフトが事前にインストールされている必要がある。これらのインス
トールに約70MB程度が必要である。</p>

<ul>
 <li>Emacs: Emacs 20.6, 20.7 21.1
 <li>日本語音声合成エンジン: Create System Document Talker for Linux
 <li>英語音声合成エンジン: IBM Viavoice Outloud
</ul>

<p> 動作確認を行ったディストリビューションは以下である。</p>

<ul>
 <li>RedHat 6.20, 7.2'(J)
 <li>Vine Linux 2.1.5
</ul>

<h3>3.2 Windows版BEP</h3>

<ul>
 <li>OS: Windows 98SE, Windows ME, Windows 2000
 <li>CPU: Pentium II 233MHz 以上
	  <br>注; Windows版(1)を安定して使用するには、Pentium II 400MHzクラスのCPUが必要。
 <li>Memory: 128MB 以上
 <li>必要なハードディスク容量: 20MB程度
</ul>

<p>以下のソフトが事前にインストールされている必要がある。これらのインス
トールに約100MBの空き領域が必要。</p>

<ul>
 <li>Emacs: Meadow 1.14, 1.15Pre1以上 (50MB程度必要)
 <li>日本語音声合成エンジン: IBM ProTalker97 Ver. 2.04以上 (40MB程度必要)
 <li>英語音声合成エンジン: Microsoft Text-to-Speech Engine (10MB程度必要)
</ul>

      <!-- Meadow44MB、SAPI8MB、HPR35MB、東芝LaLaVoice160MB、BEP14M、-->

<h2>4. 機能仕様</h2>
<h3>4.1 技術的目標</h3>
<p>
バイリンガル化されたEmacspeakがユーザにとって有用で、拡張性の高いものに
するため、いくつかの点に留意して開発を行った。
</p>
<p>
まず、BEPはバイリンガルシステムである以前に日本語音声化システムとして実
用に耐えるものでなければならない。ソースコードフリーで提供されている、
日本語環境で利用可能なLinux音声化システムは2002年2月現在においてBEP意外
に存在しない。従って、Linux上でBEPを使うユーザの多くにとって、BEPがメイ
ンの作業環境を音声化する手段となる可能性がある。日本語処理のために十分な
機能を提供できなければ、そのような利用に耐えうるものにはならない。このた
め、BEPでは文字の詳細読み、記号類の言語に依存した読み変えなどの機能をサ
ポートした。また、操作のレスポンスを向上するため、音声出力中に後のイベン
トや操作によって瞬時に先の音声を停止して次のイベントに即した読み上げを開
始する即時停止機能にも重点を置いた。
</p>
<p>
また、上のこととも関係するが、英語の聞き取りが不得意なユーザにも有用なも
のとすることも重要である。日本のスクリーンリーダーのすべてが、英語文字列
をカタカナの読みに変換し、日本語音声合成ソフトウェアを用いて発声する。
BEPはバイリンガルであるため、英語文字列は英語発音で発声するが、英語が不
得意なユーザにとってはカタカナ読みの方が情報を得やすい場面もある。また、
日本語文中に現れる英単語などは周囲と同じ日本語音声合成でカタカナ読みする
のが望ましい場合が多い。そのため、BEPでは英語文字列についてネイティブな
読みとカタカナ読みの二つを使い分けることを可能にした。
また、音声出力速度を日英独立に指定可能とした。
</p>
<p>
さらに、今回の目標は日英のバイリンガル化であるが、将来的に同じ枠組みで他
の言語環境へ拡張可能とすることをめざした。そのため、Emacspeakに英語以外
の言語サポートを加えるための変更、日本語に特化した機能をlispファイルや名
前空間のレベルで分離した。
</p>
<p>
今回の開発成果をより多くの人に利用してもらい、今後も発展していくためには、
基盤としているEmacspeakの変更をすぐに取り入れられることが望ましい。
そのため、Emacspeak本体に対しては多言語対応機能が動作するための最低限の
変更にとどめ、多言語化及び日英バイリンガル特有の機能はモジュールとして別
にロードして有効化する形とした。
</p>
<p>
以下の節ではこれらの機能を実現するためにlisp部及びスピーチサーバ部をどの
ように構成したかの概要、その外部仕様について述べる。
</p>

<h3>4.2 ELisp部バイリンガル化機能の概要</h3>

<h4>プロパティを利用した言語切り替え</h4>
<p>
Emacspeakのlisp部は大きく二つの部分から構成されている。一つは直接スピー
チサーバを制御するSS制御部、もう一つはEmacsの動作
(関数)をトリガとして呼び出され、必要な情報をSS制御部のために準備するフロ
ントエンド部である。
</p>
<p>
Emacspeakには情報の種類によって声の種類やパラメータを変えて出力する機能
がある。たとえば、プログラムを読み上げさせると、コメントの部分は抑揚のな
い棒読みで、文字列定数は女性の声でといったように区別される。この機能を
voice-lockと呼んでいる。バイリンガル拡張の実現ではこのvoice-lockにヒント
を得ている。
</p>
<p>
voice-lockではフロントエンド部でバッファの内容を解析し、デフォルト以外の
声で出力したい部分のテキストにpersonality属性を与える。SS制御部ではこの
personality属性を見知し、スピーチサーバに送るコマンドに声の種類を変更す
るためのin-textコマンドを挿入して声を変化させる。
</p>
<p>
今回開発したバイリンガル化拡張では、フロントエンド部を拡張し、バッファの
内容を見て、文字種や周囲の状況から判断してemacspeak-language属性をセット
する。この属性には値として言語名(現在はenまたはja)がセットされる。次に、
SS制御部ではこの属性の変化するところでスピーチサーバに対して言語変更を示
すコマンドを送信することで、その前後で出力すべき言語が異なることをスピー
チサーバに伝えることができる。
</p>
<p>
つまり、一度emacspeak-language属性が付与されたテキストは、これまでの音声
種別による情報提示と直行する形で言語種別の概念を持つことになる。
</p>

<h4>言語属性付与の仕組み</h4>
<p>
フロントエンド部において言語属性付与を自動的に行うことは一般に可能とは言
えない。GNU Emacsがバッファに保持している各文字の文字セット情報からその
部分が属している言語を判定することは自明な課題ではないためである。そのた
め、BEPの今回の方式では、日本語と英語のみが存在すると仮定した上で言語属
性を設定することとした。
</p>
<p>
言語の判定には主としてEmacsの持つ文字カテゴリを用いる。日本語の文字カテ
ゴリ(japanese-jisx0208, katakana-jisx0201等)に属する文字は日本語としてし
か読み上げることができないため、無条件で日本語と判定する。それ以外の文字
(asciiなど)については二つの扱い方が考えられる。一つは英語と判定してオリ
ジナルEmacspeakと同じ処理を行うこと、もう一つは日本語と判定し、カタカナ
読み(英単語、ローマ字)や日本語らしい記号読み(半角記号類)で日本語として読
み上げることである。
</p>
<p>
BEPではバッファの変更、ウインドーのスクロールやリサイズに応じて言語属性
を付与する機能が呼び出されるが、この機能を３種類の中からユーザの指定に応
じて切り替え可能とした。バッファローカル変数とすることで、バッファごと、
モードごとに設定することもできる。
また、後から追加することも可能である。現在提供し
ている三つの方式を以下に示す。
</p>
<ul>
<li>ネイティブ英語モード: ascii文字はすべて英語と判定し、英語TTSを用いて
    読み上げる。
<li>混在モード: 一定の長さ(デフォルト40文字)以下のascii文字の連続は日本
    語と判定し、カタカナ読みで日本語TTSに送る。これは、段落全体がascii文
    字であるような場合には英語で発音してほしいが、日本語文中に現れる短い
    英文字列は日本語化した語で日本語の一部として読み上げる方が自然と思わ
    れる場合が多いためである。このモードをデフォルトとしている。
<li>すべてカタカナモード: ascii文字列もすべてカタカナ読みとして日本語TTS
    で出力するモードである。プログラムなど特定の環境では日本人のユーザに
    とってこの方が実用的な場合がある。
</ul>

<h4>その他lisp部多言語対応について</h4>
<p>
本プロジェクトにおけるEmacspeakに対する拡張は、4つの部分に分けることがで
きる。それらに関して概略を述べる。
</p>
<p>
一つはEmacspeak本体に対する変更で、主にこれまでに述べた言語属性の
付与と利用に関する切り口を提供することが目的である。
また、言語属性に応じて実際に言語変更をスピーチサーバに通知したり、必要に
応じてそれぞれの言語での読み上げ速度を設定する部分は直接スピーチサーバと
関わるためにこの部分に含まれる。
この部分は今後さらに小さくまとめた上で、オリジナルEmacspeakに統合しても
らう方向で依頼する。
</p>
<p>
二つ目は多言語拡張のフレームワークに当たる部分で、言語に依存しないインター
フェースをEmacspeak本体に対して提供する。Emacspeak本体はこのレイヤの関数
のみを呼び出し、言語に依存した処理への分岐はこのレイヤで行う。抽象化され
た関数には、主に文字や記号の言語に適した読み方の取得(例: 「(」を「left
paren」と読むか「カッコ」と読むかなど)、カーソル移動時や入力時に適した読
み方の取得、言語属性付与のためのラッパーなどが含まれる。
</p>
<p>
三つ目は日本語特有の部分であり、多言語化フレームワークから呼び出される。
ここには日本語として適切な文字の読み方やカーソル移動/日本語変換時のフィー
ドバックに適した読み方の取得、前節で述べた言語属性の付与に関する三つの方
式の実装などが含まれる。
</p>
<p>
四つ目は日本語環境でよく用いられてEmacspeakがサポートしていないELispアプ
リケーションのサポートファイル群である。日本語変換システムであるtamago
V4の音声フィードバックサポート、Mew, emacs-w3m等のサポートが含まれる。
</p>

<h3>4.3 ユーザから見える変更 </h3>
<p>
本プロジェクトで開発したBilingual Emacspeak Platformではオリジナル
Emacspeakの機能を日本語英語の混在環境でもシームレスに利用可能とする方向
で拡張を行った。そのためユーザから見える部分での操作的変更は比較的少なく
なっている。
</p>
<p>
以下は多言語拡張に関連したinteractiveコマンドの一覧である。
</p>
<dl>
<dt>emacspeak-m17n-auto-put-language-mode</dt>
<dd>
バッファの変更、ウインドーのスクロール、リサイズなどのイベントに合わせて、
表示されている部分に自動的に言語プロパティを付与する機能をon/offする。同
名の変数をトグルするとともに、関連するフックの設定と解除を行う。
</dd>
<dt>emacspeak-m17n-ja-toggle-strategy</dt>
<dd>
日本語と英語のバイリンガル環境において、利用可能なput-language-strategy
をトグルする。詳しくはカスタマイズ変数の項を参照。
</dd>
 <dt>emacspeak-m17n-put-language-region</dt>
<dd>
現在の<code>emacspeak-m17n-put-language-strategy</code>に従って指定した
領域に言語プロパティを付与する。
</dd>
<dt>emacspeak-m17n-sync-rate-offset</dt>
<dd>
言語ごとの発声速度オフセットが指定されている場合に、それをスピーチサーバ
に反映するコマンドを送信する。
</dd>
</dl>
<p>
以下はバイリンガル拡張で導入されたユーザ設定可能な変数一覧である。
</p>
<dl>
<dt>dtk-speaker-process-coding-system</dt>
<dd>スピーチサーバに送信されるコマンド文字列のcoding-system。現在の
    Windows及びLinux用スピーチサーバではShift_JISを用いる。</dd>
<dt>dtk-default-language</dt>
<dd>言語属性が張られていない文字を読むときのデフォルト言語</dd>
<dt>emacspeak-m17n-auto-put-language-mode</dt>
<dd>自動的に言語属性を付与するかどうかを示す。直接変更せず、
    emacspeak-m17n-auto-put-language-modeコマンドで変更する。</dd>
<dt>emacspeak-m17n-put-language-strategy</dt>
<dd>言語属性を付与する関数を指定する。指定された関数には、引数として領域
    の先頭と最後のポイント、変更前の領域の長さが渡される。</dd>
<dt>emacspeak-m17n-put-language-internal-strategy</dt>
<dd>バッファではなくEmacsが表示するメッセージなど、言語属性が付与されな
    い状態でSS制御部に直接渡された文字列に適用する属性付与関数を指定する。
    仮定される引数はemacspeak-m17n-put-language-strategyと同じ。</dd>
<dt>emacspeak-m17n-rate-offset-alist </dt>
<dd>言語とそれに対応した速度オフセットのalist<br>
例: ((ja 0) (en -30))</dd>
<dt>emacspeak-m17n-ja-strategy-list</dt>
<dd>日本語とのバイリンガル環境で、emacspeak-m17n-ja-toggle-strategyで選
    択できる言語属性付与関数のリスト</dd>
<dt>emacspeak-m17n-ja-ke-limit</dt>
<dd>言語属性付与が混在モードの時、何文字以上のASCII文字列を英語として扱
    うかの指定。デフォルトは40</dd>
<dt>emacspeak-m17n-ja-ke-view</dt>
<dd>言語属性付与が混在モードで変更前の長さがke-limitより短い時、ポイント
    位置から上下になん行を見て判定するかの指定。デフォルトは3で、上下２
    行を見る。</dd>
</dl>

<h3>4.4 Linux Speech Serverの構成概要</h3>

<h3>4.5 LinuxSS制御コマンド一覧</h3>

<p>とりあえず張り付けておきます、井上さん、よろしく。</p>
<pre>
q { <string> } : 文字列をキューに入れる
d : キューの中身をしゃべる
s : 音声即時呈し
l { <letter> } : 文字を即時発声（大文字の区別あり）
tts_say { <string> } : 文字列を即時発声
t <freq> <msec> : トーンサイン
tts_set_speech_rate <wpm> : 音声速度設定
tts_set_punctuations <mode> : 記号類読み上げモード指定
tts_set_language <lang> : 言語指定（context.hに定義があります）
tts_set_character_scale <rate> : 'l` コマンドのスピードの倍率を設定
tts_sync_state <punc-mode> <capitaloze> <allcaps-beep> <split-caps> <rate> : 
    パラメータの一括設定（インプリメントされていないものもあります）
</pre>

<h2>5. 入手方法及びインストールの手順</h2>

<p>当プロジェクトで開発した部分はGNU GPLに従って、<a
href="http://www.argv.org/bep">BEPのWebサイト</a>で公開している</p>

<h3>5.1 Linux版BEPのインストール方法</h3>

<p>Linux版のインストール手順は大きく分けて三つのプロセスになる。日本語と
英語のTTSエンジンのインストール、Linux用スピーチサーバのコンパイルとイン
ストール、BEPのlispパッケージのインストールである。それぞれについて開設
する。</p>

<h4>日本語TTSエンジンのインストール</h4>

<p>後から書きます。Vectorで購入したときのファイルレイアウトをご存じの方
いらっしゃいませんよね？</p>

<h4>英語TTSエンジンのインストール</h4>

<p><a href="http://www.software.ibm.com/speech/dev">IBMのサイト</a>から、
ランタイムライブラリ(ViaVoice_Outloud_rtk-5.1-1.0.i386.rpm)・開発キット
(ViaVoice_Outloud_sdk-5.1-1.0.i386.rpm)を取得する。</p>

<p>それぞれRPMコマンドを使ってシステムにインストールする。</p>

<h4>Linux用スピーチサーバのインストール</h4>

<p>Makefileの必要な個所を修正する。</p>

<p>以下のコマンドでプログラムを作製し、システムにインストールする</p>

<pre>$ make
$ make install
</pre>

<h4>BEPパッケージのインストール</h4>

<h3>5.2 Windows版BEPのインストール</h3>

<p>Windows版のインストール手順は大きく分けて二つのプロセスになる。日本語と
英語のTTSエンジンのインストール、BEPのWindows版パッケージのインストール
である。それぞれについて開設する。</p>

<h4>Microsoft Speech APIのインストール</h4>

<p>Microsoftのサイトから<a
href="http://activex.microsoft.com/activex/controls/sapi/spchapi.exe">spchapi.exe</a>
をダウンロードし、実行します。自動的に必要なファイルがシステムにインストー
ルされます。システムの状況によってはシステムの再起動が必要な場合がありま
す。</p>

<h4>日本語TTSエンジンのインストール</h4>

<h4>英語TTSエンジンのインストール</h4>

<p>Microsoftのサイトから<a href="http://download.microsoft.com/msdownload/sapi/4.0/rtw/4.0a/en/msttsL.EXE">msttsL.exe</a>
をダウンロードし、実行します。システムの指示に従ってインストールを行って
ください。</p>

<h4>Bilingual Emacspeak組み込み済みMeadowのインストール</h4>

<P><p><a href="ftp://ftp.m17n.org/pub/bep/win32/release/bepw01.exe">BEP
のパッケージ</a>をダウンロードします。</p>
<p>ダウンロードしたファイルをExplorerなどで実行し、指示に従ってインストー
ルを行ってください。</p>


<h2>6. 操作仕様</h2>

<p>BEPの簡単な操作方法、バイリンガルの使い方、音声を使ったEmacsアプリケー
ションの簡単な使い方について述べる。</p>

<h3>6.1 BEPの起動方法</h3>

<h3>6.2 基本的な読み上げコマンド</h3>

<h3>言語切り替えなどのコマンド</h3>

<h3>Emacsアプリケーションの音声利用</h3>

<h2>7. 検査方法</h2>

LinuxSSのテスト方法(含む言語切り替え機能のchk)
 BEPの動作テスト方法

<h2>8. オープンソースによる福祉システム開発について</h2>

<h3>8.1 バザール型福祉システム開発の重要性</h3>

<p>福祉の市場は、(1)ユーザ数が少ない、(2)ユーザのニーズが多様で特殊である、(3)開発
者が障害者のニーズを正確に把握するのが難しい、という特徴を持つ。そのため一般的な
商品開発のプロセスで対応すると非常に高価な製品になってしまったり、障害者のニーズ
とずれた製品が市場に出てしまったりすることが多い。</p>

<p>オープンソースの世界で用いられるバザール型の開発手法は、このような特徴を持つ
福祉市場に対応した製品を出す新しい開発手法になるかもしれない。なぜならば、(1)ユー
ザ自身が開発を行う又は開発者に近い立場で開発にコミットすることでユーザのニーズを
的確・確実に開発に反映させることができる、(2)ソフトウェアはコピーが容易なので、
製品の数の多少は関係しない、(3)開発がオープンになりユーザの意見が早いサイクルで
取り入れられやすい、(4)利益を上げることが最優先事項にならないので製品の質にこだ
わることが可能である、からである。</p>

<p>オープンソースは魔法の杖ではないので、何でもオープンソースで開発すればうまく
いくわけではない。特に大事なのは、(1) 開発者が強い開発動機を持っていること、(2) 
実際に動くシステムをコミュニティに提供できること、(3) 開発者が必要なリソース(ス
キル、時間、金銭的余裕など)を持っていること、である。福祉システム開発にバザール
型の開発を適用するに当たっては、強い動機を持った、つまり自分でそれを使いたいと思っ
ている開発者がいることが重要になる。それがかなわない場合でも、実際にそのシステム
を使いたいと思っている人間がコア開発者と密接に連絡を取れるようになっていることが
大事である。BEPにおいては時節で示すように、ユーザ自身が開発者とオーバラップして
いるので、この条件を完全に満たしている。</p>

<p>本開発プロジェクトは、GNU/Linux 及びGNU Emacsのオープンな音声化システムの開発
によって、ユーザの役に立つシステムを開発するバザール型のプロジェクトである。本提
案が目指しているのは、音声出力利用のエキスパートである視覚障害者の経験や要求を満
たすような音声出力インターフェースを実現することである。オープンソース型の開発は
ユーザのニーズを取り込みやすい。特に本提案は視覚障害者自身が中心となって開発して
いるシステムであり、本提案もオープンソースの利点を生かしてユーザが本当に必要とす
るシステムを作り上げることを目指している。</p>

<h3>8.2 BEPにおけるバザール型開発の実際</h3>

<p>BEPの開発は、視覚障害者と晴眼者の共同プロジェクトで実施された。中心的な開発者
は全盲の視覚障害者であり、晴眼者1名と視覚障害者3名でほとんどの部分を開発した。こ
のほかに晴眼者約2名と視覚障害者約2名が毎月のオフライン開発者ミーティングに参加し
て開発の方針やシステムの仕様決定に参加した。BEPには2種類のメーリグリストがあり、
ユーザ用のメーリングリストである bep@argv.org は参加者数67名で、開設以来1年半で
7000通の投稿がある。開発者用のメーリングリストである bep-dev@arg.org を開設
したのは約半年前であるが、参加者数は19名で、既に1000通を超えるメールが投稿され
ている。BEPのWebサイトを開設したのは約1年前であるが、BEPのトップページは約5500 
ビュー、Windows版BEPのページは約3400ビュー、Linux版BEPのページは約1000ビューに到
達している。</p>

<p>図2のメーリングリストの投稿数や図3のWebサイトのアクセス数とBEPの発展の間に関
連が見られるので、少し詳しく述べる。<a name="Fig23"> </a></p>

<p><img src="BEP_ML.png" alt="グラフの詳細は「説明」リンクを参照"><br>
図2. メーリングリストの月別投稿数 <a href="BEP_Figs.html">(説明)</a></p>

<p><img src="BEP_Webaccess.png" alt="グラフの詳細は「説明」リンクを参照"><br> 図
3. Webサイトのアクセスカウンタの月別増加数 <a href="BEP_Figs.html">(説明)</a><br>
*; Webアクセスカウントは月末に集計。ただし2001年4月は14日に集計。</p>

<p>メーリングリストが2000年8月ごろ盛んになったのは、この時期にバイリンガルでしゃ
べるWindows版のスピーチサーバが動くようになって、はじめてBEPがある程度まともに動
くようになったからである。Linux版は2000年11月末のLinux Conferenceでの発表にあわ
せて開発を進め、同年末に日本語とカタカナ英語をなんとかしゃべるようになった。また
2001年1月にはWebサイトを作り、Windows版とLinux版のBEPをオープンソースとして一般
公開した。同時期にWindows版を障害者用のメーリングリストで案内したり、Linux
magagineの佐々木氏の記事で取り上げてもらったりしたので、メーリングリストも活発に
なっている。メーリングリストとWebともに2001年5月に活発になっている理由は ？？？？。
メーリングリストが2001年10月に投稿数が減っているように見えるのはユーザ用のBEPと
開発者用のBEP-devに分けたからである。2001年4月のWebアクセス数が減っているように
見えるのは、集計が4月14日と他の月より半月早かったためである。2001年1月にWebアク
セスが多いのは、Webサイトの製作者側のアクセス頻度が高かったことも大いに影響して
いるので、Webサイトに関して言えば、一般にアナウンスしたときにアクセス数が増えて
いる以外は、かなりコンスタントに経過している。</p>

<p>ユーザの意見やバグ報告をすぐに反映しやすいのがオープンソースの利点であるが、
Windows版の開発においては開発者に余裕がないために修正が大幅に遅れるという問題も
生じている。BEP全体でも開発者が少ないために少数の人間に大きな負荷がかかるという
問題を解消することができずにいる。WindowsのVisual C++を使ってMFCのアプリケーショ
ンを書けるプログラマーはたくさんいるが、BEPの開発に参加しようというプログラマー
は少ない。LinuxでのC++での開発でも同様のことが言える。ドキュメント作成などに関し
てもなかなか協力者を集められない。BEPでは、開発しながらBEPが備えるべき機能を議論
していった、つまり走りながら考えたので、仕様を完全に決めて外注するという開発形態
をとることは難しく、結局2,3人が議論しながら開発するしかなかった。</P>

<h2>9. 評価、今後の課題、展望</h2>

<h3>9.1 開発成果</h3>

<p>本開発プロジェクトの成果を開発項目ごとにまとめる。</p>

<dl>
  <dt>スピーチサーバの改良；
  <dd>Linux版スピーチサーバは、IBMの英語音声合成ライブラリとクリエートシステムの日
本語音声合成ライブラリに対応し、(1) 日本語と英語の音声合成エンジンの切り変え、
(2) ジャパニーズ英語とネイティブ発音の2種類の発音の切り替え、をスピーチサーバへ
のコマンドにより自由に制御できるスピーチサーバが完成した。<br>

Windows版スピーチサーバは、以下2種類のスピーチサーバを作った。Linux版と同等の機
能を持つものは開発継続中。

	(1) IBMの日本語音声合成ライブラリに対応し、日本語とネイティブ発音の英語をス
ピーチサーバで自動切換えするスピーチサーバ
	(2) 東芝の日本語音声合成ライブラリに対応し、日本語とジャパニーズ英語発音(カ
タカナ英語)をスピーチサーバで自動切換えするスピーチサーバ

  <dt>Emacs Lisp部の改良
  <dd>本システムの基盤となっているEmacspeakのEmacs Lisp部を拡張し、日本語音声化
に必要な機能を実装し、3種類のバイリンガルモードを使い分けられるように拡張した。
当開発プロジェクトの成果を本家Emacspeakに取り込む作業にも取り掛かった。

  <dt>システム全体の2ヶ国語対応
  <dd>Linux版BEPは今年度中に一般公開する。
Windows版も一般公開に向けて開発を継続する予定。

  <dt>視覚障害者用インストーラの作成
  <dd>Linux版はMakefileを使ったインストーラを今年度中に一般公開する。
Windows版は(1)のバージョンの簡単インストーラを既に一般公開している。

  <dt>ユーザテスト
  <dd>Windows版は、(1)のバージョンを日常的にBEPメンバーが使っている。(2)のバージョ
ンも開発メンバー数人が使用している。BEPメーリングリストで意見を述べてもらってい
る。Linux版はまだ開発メンバー数人が使用しているだけである。

  <dt>ユーザサポート
	<dd>BEPのWebサイト及びBEPメーリングリストでユーザサポートを実施した。詳細は
別章で述べる。

</dl>


<h3>9.2 今後の課題</h3>

<p>今回の開発でIPAの申請書に書いた中核部分は完成させることができたが、実際にユー
ザに使ってもらうためにはまだまだ改良が必要である。バイリンガル化に関して言えばま
だ拡張が不完全なところがあり、Windows版のスピーチサーバがまだ今回の拡張に対応で
きていない。本家Emacspeakへのコードの還元もこれからの課題である。また我々が使用
している商用の日本語音声合成ライブラリーにも機能が不十分な部分があり、外部の資金
を投入して改善をお願いしている。</p>

<p>Emacsは一般ユーザになじみがないアプリケーションであり、Linux自身も一般には普
及していないので、BEPに関心があっても使い始めることが出来ないユーザも存在する。
BEPを単なるソフトウェアを超えたひとつのシステムと見た場合、このようなユーザの教
育やサポートも今後の大きな課題である。</p>

<p>BEPの開発の中心メンバーは企業や大学などに所属しており、所属組織が個人での活動
をあまり認めなかったために組織の身分と個人の身分を分離することが難しく、IPAから
の委託開発と所属組織の仕事との両立にかなりの困難を生じた。</p>

<h3>9.3 音声合成への要望</h3>

<p>本システムを使用するとき、音声合成ライブラリだけがオープンソースなソフトウェ
アを使用できない。英語の音声合成ライブラリはWindows用もLinux用も無料で配布されて
いるものがあるが、日本語に関しては両OSともメーカの製品を購入しなければならない。
視覚障害者が音声でコンピュータを利用する際、音声の機能や品質は極めて重要な要素で
あるが、彼らの要求を満たすものはメーカが開発した商品以外にはない。IPAなどの資金
を得てソースのライセンスを購入するなどの方法で、商用品質の日本語音声合成ライブラ
リをオープンドメインに置けないものかと考えている。</p>

<p>視覚障害者が使用する音声合成は倍速以上の高速で音声化しても聞きやすい声を持ち、
しかも応答性がよいなどの機能が必要である。しかし現在の音声合成の研究開発は、「重
くてもよいから人間のように自然に発話する」ことに主眼が置かれ、視覚障害者のニーズ
を満たせていない。</p>


<h2>10. 開発成果の発表論文など</h2>

<ul>
  <li>T. Watanabe, K. Inoue, M. Sakamoto, M. Kiriake, H. Honda, T. Nishimoto,
and T. Kamae: Bilingual Emacspeak Platform - A universal speech interface with
GNU Emacs -, Universal Access in HCI (Lawrence Erlbaum Associates, ed. by
C. Stephandis), Vol. 3 of the Proceedings of HCI International 2001, pp.446-449.

  <li>T. Watanabe, K. Inoue, M. Sakamoto, and M. Kiriake: BEP: a practical
bilingual speech synthesis system for Japanese, Proceedings of Pacific
Association for Computational Linguistics 2001, pp.307-314.

  <li>渡辺隆行、切明政憲: 日本人用の日米2ヶ国語高機能音声化システム BEP, 情報処
理学会 音声言語情報処理研究会 (2001年10月19日、東京)、情処技報 Vol.2001/100,
pp.1-8.

  <li>渡辺隆行、井上浩一、切明政憲: 日米2ヶ国語Emacs音声化システムBEPとLinuxアク
セシビリティ向上, IPA未踏ソフトウェア創造事業シンポジウム (2001年11月21日、京都).

  <li>渡辺隆行: 日本人(視覚障害者)用の日英2ヶ国語音声化システムBEP, 第45回ロービ
ジョン研究会 (2002年1月12日、東京女子大学).
</ul>


<hr>
<address><a href="http://www.sfc.keio.ac.jp/~wata7be/">WATANABE Takayuki &lt;takayuki@la.shonna-it.ac.jp&gt;</a></address>
<!-- hhmts start --> Last modified: Sat Feb 09 18:09:26 JST 2002 <!-- hhmts end --> 
</body>
</html>
